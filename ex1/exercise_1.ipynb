{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lores\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package semcor to\n",
      "[nltk_data]     C:\\Users\\lores\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package semcor is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lores\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\lores\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lores\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import semcor\n",
    "from nltk.corpus.reader.wordnet import Synset\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "from scipy import stats as st\n",
    "nltk.download('wordnet')\n",
    "nltk.download('semcor')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Part\n",
    "- The exercise consists of implementing three similarity measures based on WordNet:\n",
    "    - WU & Palmer similarity\n",
    "    - Shortest Path similarity\n",
    "    - Leacock & Chodorow similarity\n",
    "- For each of these similarity measures, calculate Spearman's correlation indices and Pearson's correlation indices between the results obtained and the 'target' results in the dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Human (mean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>sex</td>\n",
       "      <td>6.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tiger</td>\n",
       "      <td>cat</td>\n",
       "      <td>7.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tiger</td>\n",
       "      <td>tiger</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book</td>\n",
       "      <td>paper</td>\n",
       "      <td>7.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>computer</td>\n",
       "      <td>keyboard</td>\n",
       "      <td>7.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>shower</td>\n",
       "      <td>flood</td>\n",
       "      <td>6.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>weather</td>\n",
       "      <td>forecast</td>\n",
       "      <td>8.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>disaster</td>\n",
       "      <td>area</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>governor</td>\n",
       "      <td>office</td>\n",
       "      <td>6.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>architecture</td>\n",
       "      <td>century</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word 1    Word 2  Human (mean)\n",
       "0            love       sex          6.77\n",
       "1           tiger       cat          7.35\n",
       "2           tiger     tiger         10.00\n",
       "3            book     paper          7.46\n",
       "4        computer  keyboard          7.62\n",
       "..            ...       ...           ...\n",
       "348        shower     flood          6.03\n",
       "349       weather  forecast          8.34\n",
       "350      disaster      area          6.25\n",
       "351      governor    office          6.34\n",
       "352  architecture   century          3.78\n",
       "\n",
       "[353 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reading the file\n",
    "df = pd.read_csv('dataset\\wordsim353.csv')\n",
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the function to get the max depth of the synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_depth_synset(synset: Synset) -> int:\n",
    "    return max(len(path) for path in synset.hypernym_paths())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the function to get the least common subsumer of two synsets\n",
    "\n",
    "We loop through the paths of the first synset, and for each path we check if it is in the second synset. If it is, we return it.\n",
    "If the synsets have no common subsumer, we return the max depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LCS(syn1: Synset, syn2: Synset) -> Synset | None:\n",
    "    path1 = syn1.hypernym_paths()\n",
    "    path2 = syn2.hypernym_paths()\n",
    "    result = []\n",
    "\n",
    "    # We loop through the paths of the first synset\n",
    "    for pat1 in path1:\n",
    "        x = pat1\n",
    "        x.reverse()\n",
    "        found = False\n",
    "        for syn in x:\n",
    "            if(not found):\n",
    "                # We loop through the paths of the second synset\n",
    "                for pat2 in path2:\n",
    "                    if(syn in pat2):\n",
    "                        result.append(syn)\n",
    "                        found = True\n",
    "                        break\n",
    "            else:\n",
    "                break\n",
    "    if not result:\n",
    "            return None\n",
    "    else:\n",
    "         max_depth = max(max_depth_synset(s) for s in result)\n",
    "         max_hypernym = max(s for s in result if max_depth_synset(s) == max_depth)\n",
    "         return max_hypernym"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path Length\n",
    "\n",
    "We get the least common ancestor of the two synsets, and then we calculate the path length of each synset to the least common subsumer. We sum the two min path lengths and return the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_len(syn1: Synset, syn2: Synset) -> int:\n",
    "    path1 = syn1.hypernym_paths()\n",
    "    path2 = syn2.hypernym_paths()\n",
    "    result_syn1 = []\n",
    "    result_syn2 = []\n",
    "\n",
    "    common_ancestor = LCS(syn1,syn2)\n",
    "\n",
    "    if(common_ancestor is None):\n",
    "        return None\n",
    "    else:\n",
    "        for pat1 in path1:\n",
    "            if(common_ancestor in pat1):\n",
    "                result_syn1.append(pat1.index(syn1)-pat1.index(common_ancestor))\n",
    "        for pat2 in path2:\n",
    "            if(common_ancestor in pat2):\n",
    "                result_syn2.append(pat2.index(syn2)-pat2.index(common_ancestor))\n",
    "        return min(result_syn1) + min(result_syn2)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_max = max(max(len(hyp_path) for hyp_path in ss.hypernym_paths()) for ss in wn.all_synsets())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wu Palmer\n",
    "\n",
    "$$ LCS(s1, s2) = {2 * depth(LCS(s1,s2)) \\over depth(s1) + depth(s2)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wu_palmer(syn1: Synset, syn2: Synset) -> float:\n",
    "    # We get all the synsets of the two words\n",
    "    depht1 = max_depth_synset(syn1)\n",
    "    depht2 = max_depth_synset(syn2)\n",
    "    \n",
    "    # Finding the least common subsumer of the two synsets\n",
    "    common_ancestor = LCS(syn1,syn2)\n",
    "    if common_ancestor is None:\n",
    "        return 0\n",
    "    return 2 * max_depth_synset(common_ancestor) / ( depht1 + depht2 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortest Path\n",
    "\n",
    "$$ LCS(s1, s2) = 2 * depthMax - len(s1,s2) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path(syn1: Synset, syn2: Synset) -> int:\n",
    "    pat = path_len(syn1,syn2)\n",
    "    if pat is None:\n",
    "        return 0\n",
    "    elif (pat == 0):\n",
    "        return 2 * depth_max\n",
    "    elif (pat == depth_max):\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * depth_max - pat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leakcock & Chodorow\n",
    "\n",
    "$$ sim_LC(s1, s2) = -log(\\frac{len(s1,s2)}{2*depthMax}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leakcock_chodorow (syn1: Synset, syn2: Synset) -> float:\n",
    "    pat = path_len(syn1,syn2)\n",
    "    if pat is None:\n",
    "        return 0\n",
    "    elif (pat == 0):\n",
    "        return -math.log((1)/(2 * depth_max + 1))\n",
    "    else:\n",
    "        return -math.log((pat)/(2 * depth_max))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycle for every synset of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synsets_cycle(word1: str, word2: str, metric: callable) -> float | str:\n",
    "    syn1 = wn.synsets(word1)\n",
    "    syn2 = wn.synsets(word2)\n",
    "    result = []\n",
    "    for s1 in syn1:\n",
    "        for s2 in syn2:\n",
    "            result.append(metric(s1,s2))\n",
    "    if not result:\n",
    "        return 0\n",
    "    else:\n",
    "        return max(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WU Palmer between dog and cat: 0.8571428571428571\n",
      "WU Palmer between stock and live: 0.2857142857142857\n",
      "Shortest Path between Jerusalem and Palestinian: 24\n",
      "Leakcock Chodorow between dog and cat: 2.3025850929940455\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "print(\"WU Palmer between dog and cat:\", synsets_cycle('dog','cat', wu_palmer))\n",
    "print(\"WU Palmer between stock and live:\", synsets_cycle('stock','live', wu_palmer))\n",
    "print(\"Shortest Path between Jerusalem and Palestinian:\", synsets_cycle('Jerusalem','Palestinian', shortest_path))\n",
    "print(\"Leakcock Chodorow between dog and cat:\", synsets_cycle('dog','cat', leakcock_chodorow))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over all pair of words in the dataset and i print the three similarity measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Human (mean)</th>\n",
       "      <th>WU Palmer</th>\n",
       "      <th>Shortest Path</th>\n",
       "      <th>Leakcock Chodorow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>sex</td>\n",
       "      <td>6.77</td>\n",
       "      <td>9.230769</td>\n",
       "      <td>9.75</td>\n",
       "      <td>9.933507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tiger</td>\n",
       "      <td>cat</td>\n",
       "      <td>7.35</td>\n",
       "      <td>9.655172</td>\n",
       "      <td>9.75</td>\n",
       "      <td>9.933507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tiger</td>\n",
       "      <td>tiger</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book</td>\n",
       "      <td>paper</td>\n",
       "      <td>7.46</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>9.50</td>\n",
       "      <td>8.066983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>computer</td>\n",
       "      <td>keyboard</td>\n",
       "      <td>7.62</td>\n",
       "      <td>8.235294</td>\n",
       "      <td>9.25</td>\n",
       "      <td>6.975136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>shower</td>\n",
       "      <td>flood</td>\n",
       "      <td>6.03</td>\n",
       "      <td>6.363636</td>\n",
       "      <td>9.00</td>\n",
       "      <td>6.200459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>weather</td>\n",
       "      <td>forecast</td>\n",
       "      <td>8.34</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>6.75</td>\n",
       "      <td>3.026547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>disaster</td>\n",
       "      <td>area</td>\n",
       "      <td>6.25</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.333935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>governor</td>\n",
       "      <td>office</td>\n",
       "      <td>6.34</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>7.75</td>\n",
       "      <td>4.016766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>architecture</td>\n",
       "      <td>century</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.076923</td>\n",
       "      <td>7.75</td>\n",
       "      <td>4.016766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word 1    Word 2  Human (mean)  WU Palmer  Shortest Path   \n",
       "0            love       sex          6.77   9.230769           9.75  \\\n",
       "1           tiger       cat          7.35   9.655172           9.75   \n",
       "2           tiger     tiger         10.00  10.000000          10.00   \n",
       "3            book     paper          7.46   8.750000           9.50   \n",
       "4        computer  keyboard          7.62   8.235294           9.25   \n",
       "..            ...       ...           ...        ...            ...   \n",
       "348        shower     flood          6.03   6.363636           9.00   \n",
       "349       weather  forecast          8.34   1.333333           6.75   \n",
       "350      disaster      area          6.25   5.000000           8.00   \n",
       "351      governor    office          6.34   5.263158           7.75   \n",
       "352  architecture   century          3.78   3.076923           7.75   \n",
       "\n",
       "     Leakcock Chodorow  \n",
       "0             9.933507  \n",
       "1             9.933507  \n",
       "2            10.000000  \n",
       "3             8.066983  \n",
       "4             6.975136  \n",
       "..                 ...  \n",
       "348           6.200459  \n",
       "349           3.026547  \n",
       "350           4.333935  \n",
       "351           4.016766  \n",
       "352           4.016766  \n",
       "\n",
       "[353 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through the dataset and calculate the similarity for each pair of words using the three metrics and i add the result to a new dataframe\n",
    "df_metrics = pd.DataFrame(columns=['Word 1', 'Word 2', \"Human (mean)\", \"WU Palmer\", \"Shortest Path\", \"Leakcock Chodorow\"])\n",
    "for index, row in df.iterrows():\n",
    "    df_metrics.loc[len(df_metrics)] = {'Word 1': row['Word 1'], 'Word 2': row['Word 2'], \"Human (mean)\": row['Human (mean)'], \"WU Palmer\": synsets_cycle(row['Word 1'], row['Word 2'], wu_palmer) * 10, \"Shortest Path\": (synsets_cycle(row['Word 1'], row['Word 2'], shortest_path) /40) * 10, \"Leakcock Chodorow\": (synsets_cycle(row['Word 1'], row['Word 2'], leakcock_chodorow) / math.log(41)) * 10}\n",
    "display(df_metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of correlation with Spearman and Pearson metrics between the human similarity and the similarity calculated by the three metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "WU Palmer Metric:\n",
      "Spearman Correlation: SignificanceResult(statistic=0.34531446776235897, pvalue=2.5376440594705738e-11)\n",
      "The distribution of the WU Palmer metric is significantly different from the distribution of the Human Similarity.\n",
      "\n",
      "Pearson Correlation: PearsonRResult(statistic=0.28732609798215053, pvalue=3.895408936985221e-08)\n",
      "The distribution of the WU Palmer metric is significantly different from the distribution of the Human Similarity.\n",
      "-------------------------------------------\n",
      "Shortest Path Metric:\n",
      "Spearman Correlation: SignificanceResult(statistic=0.2883010732370922, pvalue=3.4876313366885126e-08)\n",
      "The distribution of the Shortest Path metric is significantly different from the distribution of the Human Similarity.\n",
      "\n",
      "Pearson Correlation: PearsonRResult(statistic=0.16411938908972765, pvalue=0.0019775111177550756)\n",
      "The distribution of the Shortest Path metric is significantly different from the distribution of the Human Similarity.\n",
      "-------------------------------------------\n",
      "Leakcock Chodorow Metric:\n",
      "Spearman Correlation: SignificanceResult(statistic=0.2883010732370922, pvalue=3.4876313366885126e-08)\n",
      "The distribution of the Leakcock Chodorow metric is significantly different from the distribution of the Human Similarity.\n",
      "\n",
      "Pearson Correlation: PearsonRResult(statistic=0.317375647242182, pvalue=1.0592028515546679e-09)\n",
      "The distribution of the Leakcock Chodorow metric is significantly different from the distribution of the Human Similarity.\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation between the human similarity and the similarity calculated by the three metrics\n",
    "\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"WU Palmer Metric:\")\n",
    "spearman_correlation = st.spearmanr(df_metrics[\"WU Palmer\"], df_metrics[\"Human (mean)\"])\n",
    "print(\"Spearman Correlation:\", spearman_correlation)\n",
    "if spearman_correlation[1] < 0.05:\n",
    "    print(\"The distribution of the WU Palmer metric is significantly different from the distribution of the Human Similarity.\\n\")\n",
    "else:\n",
    "    print(\"The distribution of the WU Palmer metric is almost the same as the distribution of the Human Similarity.\\n\")\n",
    "pearson_correlation = st.pearsonr(df_metrics[\"WU Palmer\"], df_metrics[\"Human (mean)\"])\n",
    "print(\"Pearson Correlation:\", pearson_correlation)\n",
    "if pearson_correlation[1] < 0.05:\n",
    "    print(\"The distribution of the WU Palmer metric is significantly different from the distribution of the Human Similarity.\")\n",
    "else:\n",
    "    print(\"The distribution of the WU Palmer metric is almost the same as the distribution of the Human Similarity.\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "print(\"Shortest Path Metric:\")\n",
    "spearman_correlation = st.spearmanr(df_metrics[\"Shortest Path\"], df_metrics[\"Human (mean)\"])\n",
    "print(\"Spearman Correlation:\", spearman_correlation)\n",
    "if spearman_correlation[1] < 0.05:\n",
    "    print(\"The distribution of the Shortest Path metric is significantly different from the distribution of the Human Similarity.\\n\")\n",
    "else:\n",
    "    print(\"The distribution of the Shortest Path metric is almost the same as the distribution of the Human Similarity.\\n\")\n",
    "pearson_correlation = st.pearsonr(df_metrics[\"Shortest Path\"], df_metrics[\"Human (mean)\"])\n",
    "print(\"Pearson Correlation:\", pearson_correlation)\n",
    "if pearson_correlation[1] < 0.05:\n",
    "    print(\"The distribution of the Shortest Path metric is significantly different from the distribution of the Human Similarity.\")\n",
    "else:\n",
    "    print(\"The distribution of the Shortest Path metric is almost the same as the distribution of the Human Similarity.\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "print(\"Leakcock Chodorow Metric:\")\n",
    "spearman_correlation = st.spearmanr(df_metrics[\"Leakcock Chodorow\"], df_metrics[\"Human (mean)\"])\n",
    "print(\"Spearman Correlation:\", spearman_correlation)\n",
    "if spearman_correlation[1] < 0.05:\n",
    "    print(\"The distribution of the Leakcock Chodorow metric is significantly different from the distribution of the Human Similarity.\\n\")\n",
    "else:\n",
    "    print(\"The distribution of the Leakcock Chodorow metric is almost the same as the distribution of the Human Similarity.\\n\")\n",
    "pearson_correlation = st.pearsonr(df_metrics[\"Leakcock Chodorow\"], df_metrics[\"Human (mean)\"])\n",
    "print(\"Pearson Correlation:\", pearson_correlation)\n",
    "if pearson_correlation[1] < 0.05:\n",
    "    print(\"The distribution of the Leakcock Chodorow metric is significantly different from the distribution of the Human Similarity.\")\n",
    "else:\n",
    "    print(\"The distribution of the Leakcock Chodorow metric is almost the same as the distribution of the Human Similarity.\")\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Part\n",
    "\n",
    "- Implementing Lesk's algorithm (not from NLTK).\n",
    "    1. Extract 50 sentences from the SemCor corpus (corpus annotated with WN synsets) and disambiguate (at least) one noun per sentence. Calculate the accuracy of the implemented system based on the senses annotated in SemCor.\n",
    "    SemCor is available at the URL: http://web.eecs.umich.edu/~mihalcea/downloads.html\n",
    "    2. Randomize the selection of the 50 sentences and the selection of the term to be disambiguated, and return the average accuracy over (for example) 10 runs of the program."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining support function for cleaning the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I clean the sentences removing the punctuation and the stop words\n",
    "\n",
    "def clean_sentence(sentence: str | list) -> list:\n",
    "    sentence_without_puntuaction = re.sub(r'[^\\w\\s]', '', str(sentence)).strip()\n",
    "    word_tokens = word_tokenize(sentence_without_puntuaction)\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "    return filtered_sentence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Lesk Algorithm\n",
    "\n",
    "We take all the synsets of the word.\n",
    "Then make a for loop for each synset computing the overlap between the gloss and the context(sentence).\n",
    "We return the synset with the highest overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I use the Lesk algorithm to find the best sense of the word in the sentence\n",
    "\n",
    "def lesk(word: str, sentence: list, clean: bool) -> Synset:\n",
    "    synsets = wn.synsets(word)\n",
    "    if not synsets:\n",
    "        return None\n",
    "    best_sense = synsets[0]\n",
    "    max_overlap = 0\n",
    "    for synset in synsets:\n",
    "        overlap = 0\n",
    "        # Cleaning example in wordnet \n",
    "        for definition_word in clean_sentence(synset.definition()) if clean else synset.definition().split():\n",
    "            if definition_word in sentence:\n",
    "                overlap += 1\n",
    "        for example_word in clean_sentence(synset.examples()) if clean else synset.examples():\n",
    "            if clean:\n",
    "                if example_word in sentence:\n",
    "                    overlap += 1\n",
    "            else:\n",
    "                for example_word in example_word.split():\n",
    "                    if example_word in sentence:\n",
    "                        overlap += 1\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            best_sense = synset\n",
    "        \n",
    "    return best_sense"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the cycle for disambiguate the sostantive words in the sentences. \n",
    "I use the Lesk Algorithm for the best synset and I compare it with the synset of the SemCor corpus. \n",
    "\n",
    "To verify accuracy, we used two different methods. \n",
    "\n",
    "- With the first (**get_accuracy_pos_tag**) one we take the sentence, calculate the pos tagging with the nltk libraries and go to calculate the accuracy with lesk.\n",
    "- With the second (**get_accuracy_from_corpus**) we go to take the nouns from the annotated corpus of semCor and then calculate the accuracy with lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I select the sostantive words with pos_tag and I use the lesk algorithm to find the best synset\n",
    "# I use the synset of the semcor corpus to compare the results\n",
    "\n",
    "def get_accuracy_pos_tag(index_list: list, sentence_list: list, sentence_tagged_list: list, clean: bool) -> float:\n",
    "    points = 0\n",
    "    total = 0\n",
    "    for index in index_list:\n",
    "        # We get the sentence from the dataframe\n",
    "        sentence = sentence_list.iloc[index][\"sentences\"]\n",
    "\n",
    "        # We get the tagged sentence from the dataframe\n",
    "        list_of_sentence_tagged = sentence_tagged_list.iloc[index][\"tagged_sentences\"]\n",
    "\n",
    "        # We get the pos_tag of the sentence\n",
    "        sentence_tagged = nltk.pos_tag(clean_sentence(sentence)) if clean else nltk.pos_tag(word_tokenize(' '.join(sentence)))\n",
    "        for word, tag in sentence_tagged:\n",
    "            # Only for noun\n",
    "            if tag == 'NN':\n",
    "                # We get the best synset\n",
    "                best_synset = lesk(word, clean_sentence(sentence) if clean else sentence, clean)\n",
    "\n",
    "                # If there is no synset we skip the word\n",
    "                if best_synset is None:\n",
    "                    break\n",
    "\n",
    "                # We compare the synset with the synset of the semcor corpus\n",
    "                for tag in list_of_sentence_tagged:\n",
    "                    if tag.pos()[0][0] == word and tag.pos()[0][1] == 'NN' and hasattr(tag.label(), 'synset') and best_synset == tag.label().synset():\n",
    "                        # If the synset are the same we add a point\n",
    "                        points += 1 \n",
    "                \n",
    "                # We add a total, because we have to calculate the accuracy\n",
    "                total += 1 \n",
    "    print(\"Total number of words to disambiguate:\", total)\n",
    "    print(\"Number of words correctly disambiguated:\", points)\n",
    "    accuracy = points/total\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# I select the sostantive words directly from the semcor corpus and I use the lesk algorithm to to find the best synset.\n",
    "# I use the synset of the semcor corpus to compare the results\n",
    "\n",
    "def get_accuracy_from_corpus(index_list: list, sentence_list: list, sentence_tagged_list: list, clean: bool) -> float:\n",
    "    points = 0\n",
    "    total = 0\n",
    "    for index in index_list:\n",
    "        sentence = sentence_list.iloc[index][\"sentences\"]\n",
    "        list_of_sentence_tagged = sentence_tagged_list.iloc[index][\"tagged_sentences\"]\n",
    "        for tag in list_of_sentence_tagged: \n",
    "            if hasattr(tag, 'label') and hasattr(tag.label(), 'synset'): \n",
    "                # We get the synset of the semcor corpus\n",
    "                true_synset_word = tag.label().synset()\n",
    "\n",
    "                # Only for noun\n",
    "                if true_synset_word.name().split('.')[1] == 'n': \n",
    "                    # We get the lemma of the word\n",
    "                    word_lemma = tag.label().name()\n",
    "                    best_synset = lesk(word_lemma, clean_sentence(sentence) if clean else sentence, clean)\n",
    "                    if best_synset is None:\n",
    "                        break \n",
    "                    if best_synset == true_synset_word:\n",
    "                        points += 1 \n",
    "                    total += 1\n",
    "    print(\"Total number of words to disambiguate:\", total)\n",
    "    print(\"Number of words correctly disambiguated:\", points)\n",
    "    accuracy = points/total\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the range of index for extracting the sentences and the two pandas dataframe of sentences and tagged sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I extract only first 50 sentences\n",
    "list_of_index = range(0,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For efficiency, I create two pandas dataframe to store the sentences and the tagged sentences\n",
    "# Accessing directly to the corpus is very slow\n",
    "sentences_semcor = pd.DataFrame({\"sentences\": semcor.sents()})\n",
    "tagged_sentences_semcor = pd.DataFrame({'tagged_sentences': list(semcor.tagged_sents(tag='both'))})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the first 50 sentences without randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 321\n",
      "Number of words correctly disambiguated: 209\n",
      "Accuracy: 0.6510903426791277\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 193\n",
      "Number of words correctly disambiguated: 85\n",
      "Accuracy: 0.44041450777202074\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 321\n",
      "Number of words correctly disambiguated: 149\n",
      "Accuracy: 0.46417445482866043\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 197\n",
      "Number of words correctly disambiguated: 78\n",
      "Accuracy: 0.39593908629441626\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------------------------------\")\n",
    "print(\"Sostantive words extracted from the corpus\\n\")\n",
    "get_accuracy_from_corpus(list_of_index, sentences_semcor, tagged_sentences_semcor, True)\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Sostantive words extracted from the POS Tagging\\n\")\n",
    "get_accuracy_pos_tag(list_of_index, sentences_semcor, tagged_sentences_semcor, True)\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Sostantive words extracted from the corpus without cleaning the sentences\\n\")\n",
    "get_accuracy_from_corpus(list_of_index, sentences_semcor, tagged_sentences_semcor, False)\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Sostantive words extracted from the POS Tagging without cleaning the sentences\\n\")\n",
    "get_accuracy_pos_tag(list_of_index, sentences_semcor, tagged_sentences_semcor, False)\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I run the algorithm 50 times and I calculate the average accuracy with randomized extraction of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Iteraction number: 1\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 90\n",
      "Number of words correctly disambiguated: 52\n",
      "Accuracy: 0.5777777777777777\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 139\n",
      "Number of words correctly disambiguated: 15\n",
      "Accuracy: 0.1079136690647482\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 90\n",
      "Number of words correctly disambiguated: 31\n",
      "Accuracy: 0.34444444444444444\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 153\n",
      "Number of words correctly disambiguated: 13\n",
      "Accuracy: 0.08496732026143791\n",
      "-------------------------------------------\n",
      "Iteraction number: 2\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 126\n",
      "Number of words correctly disambiguated: 68\n",
      "Accuracy: 0.5396825396825397\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 156\n",
      "Number of words correctly disambiguated: 27\n",
      "Accuracy: 0.17307692307692307\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 126\n",
      "Number of words correctly disambiguated: 62\n",
      "Accuracy: 0.49206349206349204\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 159\n",
      "Number of words correctly disambiguated: 33\n",
      "Accuracy: 0.20754716981132076\n",
      "-------------------------------------------\n",
      "Iteraction number: 3\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 99\n",
      "Number of words correctly disambiguated: 59\n",
      "Accuracy: 0.5959595959595959\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 127\n",
      "Number of words correctly disambiguated: 27\n",
      "Accuracy: 0.2125984251968504\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 99\n",
      "Number of words correctly disambiguated: 52\n",
      "Accuracy: 0.5252525252525253\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 132\n",
      "Number of words correctly disambiguated: 24\n",
      "Accuracy: 0.18181818181818182\n",
      "-------------------------------------------\n",
      "Iteraction number: 4\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 113\n",
      "Number of words correctly disambiguated: 68\n",
      "Accuracy: 0.6017699115044248\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 129\n",
      "Number of words correctly disambiguated: 23\n",
      "Accuracy: 0.17829457364341086\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 113\n",
      "Number of words correctly disambiguated: 50\n",
      "Accuracy: 0.4424778761061947\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 136\n",
      "Number of words correctly disambiguated: 16\n",
      "Accuracy: 0.11764705882352941\n",
      "-------------------------------------------\n",
      "Iteraction number: 5\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 92\n",
      "Number of words correctly disambiguated: 56\n",
      "Accuracy: 0.6086956521739131\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 125\n",
      "Number of words correctly disambiguated: 32\n",
      "Accuracy: 0.256\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 92\n",
      "Number of words correctly disambiguated: 48\n",
      "Accuracy: 0.5217391304347826\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 128\n",
      "Number of words correctly disambiguated: 31\n",
      "Accuracy: 0.2421875\n",
      "-------------------------------------------\n",
      "Iteraction number: 6\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 107\n",
      "Number of words correctly disambiguated: 53\n",
      "Accuracy: 0.4953271028037383\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 123\n",
      "Number of words correctly disambiguated: 27\n",
      "Accuracy: 0.21951219512195122\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 107\n",
      "Number of words correctly disambiguated: 42\n",
      "Accuracy: 0.3925233644859813\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 131\n",
      "Number of words correctly disambiguated: 22\n",
      "Accuracy: 0.16793893129770993\n",
      "-------------------------------------------\n",
      "Iteraction number: 7\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 164\n",
      "Number of words correctly disambiguated: 94\n",
      "Accuracy: 0.573170731707317\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 166\n",
      "Number of words correctly disambiguated: 41\n",
      "Accuracy: 0.2469879518072289\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 164\n",
      "Number of words correctly disambiguated: 62\n",
      "Accuracy: 0.3780487804878049\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 169\n",
      "Number of words correctly disambiguated: 33\n",
      "Accuracy: 0.1952662721893491\n",
      "-------------------------------------------\n",
      "Iteraction number: 8\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 94\n",
      "Number of words correctly disambiguated: 50\n",
      "Accuracy: 0.5319148936170213\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 126\n",
      "Number of words correctly disambiguated: 21\n",
      "Accuracy: 0.16666666666666666\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 94\n",
      "Number of words correctly disambiguated: 38\n",
      "Accuracy: 0.40425531914893614\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 154\n",
      "Number of words correctly disambiguated: 21\n",
      "Accuracy: 0.13636363636363635\n",
      "-------------------------------------------\n",
      "Iteraction number: 9\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 112\n",
      "Number of words correctly disambiguated: 71\n",
      "Accuracy: 0.6339285714285714\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 124\n",
      "Number of words correctly disambiguated: 29\n",
      "Accuracy: 0.23387096774193547\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 112\n",
      "Number of words correctly disambiguated: 50\n",
      "Accuracy: 0.44642857142857145\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 134\n",
      "Number of words correctly disambiguated: 28\n",
      "Accuracy: 0.208955223880597\n",
      "-------------------------------------------\n",
      "Iteraction number: 10\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 144\n",
      "Number of words correctly disambiguated: 80\n",
      "Accuracy: 0.5555555555555556\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 145\n",
      "Number of words correctly disambiguated: 30\n",
      "Accuracy: 0.20689655172413793\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 144\n",
      "Number of words correctly disambiguated: 50\n",
      "Accuracy: 0.3472222222222222\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 142\n",
      "Number of words correctly disambiguated: 24\n",
      "Accuracy: 0.16901408450704225\n",
      "-------------------------------------------\n",
      "Iteraction number: 11\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 110\n",
      "Number of words correctly disambiguated: 63\n",
      "Accuracy: 0.5727272727272728\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 148\n",
      "Number of words correctly disambiguated: 36\n",
      "Accuracy: 0.24324324324324326\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 110\n",
      "Number of words correctly disambiguated: 43\n",
      "Accuracy: 0.39090909090909093\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 161\n",
      "Number of words correctly disambiguated: 31\n",
      "Accuracy: 0.19254658385093168\n",
      "-------------------------------------------\n",
      "Iteraction number: 12\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 123\n",
      "Number of words correctly disambiguated: 78\n",
      "Accuracy: 0.6341463414634146\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 122\n",
      "Number of words correctly disambiguated: 30\n",
      "Accuracy: 0.2459016393442623\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 123\n",
      "Number of words correctly disambiguated: 53\n",
      "Accuracy: 0.43089430894308944\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 143\n",
      "Number of words correctly disambiguated: 31\n",
      "Accuracy: 0.21678321678321677\n",
      "-------------------------------------------\n",
      "Iteraction number: 13\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 81\n",
      "Number of words correctly disambiguated: 45\n",
      "Accuracy: 0.5555555555555556\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 119\n",
      "Number of words correctly disambiguated: 10\n",
      "Accuracy: 0.08403361344537816\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 81\n",
      "Number of words correctly disambiguated: 29\n",
      "Accuracy: 0.35802469135802467\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 141\n",
      "Number of words correctly disambiguated: 16\n",
      "Accuracy: 0.11347517730496454\n",
      "-------------------------------------------\n",
      "Iteraction number: 14\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 107\n",
      "Number of words correctly disambiguated: 65\n",
      "Accuracy: 0.6074766355140186\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 132\n",
      "Number of words correctly disambiguated: 26\n",
      "Accuracy: 0.19696969696969696\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 107\n",
      "Number of words correctly disambiguated: 49\n",
      "Accuracy: 0.45794392523364486\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 140\n",
      "Number of words correctly disambiguated: 27\n",
      "Accuracy: 0.19285714285714287\n",
      "-------------------------------------------\n",
      "Iteraction number: 15\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 123\n",
      "Number of words correctly disambiguated: 69\n",
      "Accuracy: 0.5609756097560976\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 149\n",
      "Number of words correctly disambiguated: 32\n",
      "Accuracy: 0.21476510067114093\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 123\n",
      "Number of words correctly disambiguated: 58\n",
      "Accuracy: 0.4715447154471545\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 162\n",
      "Number of words correctly disambiguated: 39\n",
      "Accuracy: 0.24074074074074073\n",
      "-------------------------------------------\n",
      "Iteraction number: 16\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 116\n",
      "Number of words correctly disambiguated: 65\n",
      "Accuracy: 0.5603448275862069\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 119\n",
      "Number of words correctly disambiguated: 27\n",
      "Accuracy: 0.226890756302521\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 116\n",
      "Number of words correctly disambiguated: 51\n",
      "Accuracy: 0.4396551724137931\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 133\n",
      "Number of words correctly disambiguated: 31\n",
      "Accuracy: 0.23308270676691728\n",
      "-------------------------------------------\n",
      "Iteraction number: 17\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 97\n",
      "Number of words correctly disambiguated: 59\n",
      "Accuracy: 0.6082474226804123\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 116\n",
      "Number of words correctly disambiguated: 21\n",
      "Accuracy: 0.1810344827586207\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 97\n",
      "Number of words correctly disambiguated: 36\n",
      "Accuracy: 0.3711340206185567\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 130\n",
      "Number of words correctly disambiguated: 24\n",
      "Accuracy: 0.18461538461538463\n",
      "-------------------------------------------\n",
      "Iteraction number: 18\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 122\n",
      "Number of words correctly disambiguated: 73\n",
      "Accuracy: 0.5983606557377049\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 119\n",
      "Number of words correctly disambiguated: 25\n",
      "Accuracy: 0.21008403361344538\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 122\n",
      "Number of words correctly disambiguated: 63\n",
      "Accuracy: 0.5163934426229508\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 115\n",
      "Number of words correctly disambiguated: 35\n",
      "Accuracy: 0.30434782608695654\n",
      "-------------------------------------------\n",
      "Iteraction number: 19\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 121\n",
      "Number of words correctly disambiguated: 68\n",
      "Accuracy: 0.5619834710743802\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 129\n",
      "Number of words correctly disambiguated: 26\n",
      "Accuracy: 0.20155038759689922\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 121\n",
      "Number of words correctly disambiguated: 46\n",
      "Accuracy: 0.38016528925619836\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 140\n",
      "Number of words correctly disambiguated: 24\n",
      "Accuracy: 0.17142857142857143\n",
      "-------------------------------------------\n",
      "Iteraction number: 20\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 105\n",
      "Number of words correctly disambiguated: 59\n",
      "Accuracy: 0.5619047619047619\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 118\n",
      "Number of words correctly disambiguated: 24\n",
      "Accuracy: 0.2033898305084746\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 105\n",
      "Number of words correctly disambiguated: 41\n",
      "Accuracy: 0.3904761904761905\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 139\n",
      "Number of words correctly disambiguated: 21\n",
      "Accuracy: 0.1510791366906475\n",
      "-------------------------------------------\n",
      "Iteraction number: 21\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 121\n",
      "Number of words correctly disambiguated: 68\n",
      "Accuracy: 0.5619834710743802\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 136\n",
      "Number of words correctly disambiguated: 32\n",
      "Accuracy: 0.23529411764705882\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 121\n",
      "Number of words correctly disambiguated: 38\n",
      "Accuracy: 0.3140495867768595\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 157\n",
      "Number of words correctly disambiguated: 22\n",
      "Accuracy: 0.14012738853503184\n",
      "-------------------------------------------\n",
      "Iteraction number: 22\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 100\n",
      "Number of words correctly disambiguated: 49\n",
      "Accuracy: 0.49\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 128\n",
      "Number of words correctly disambiguated: 16\n",
      "Accuracy: 0.125\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 100\n",
      "Number of words correctly disambiguated: 36\n",
      "Accuracy: 0.36\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 144\n",
      "Number of words correctly disambiguated: 16\n",
      "Accuracy: 0.1111111111111111\n",
      "-------------------------------------------\n",
      "Iteraction number: 23\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 99\n",
      "Number of words correctly disambiguated: 59\n",
      "Accuracy: 0.5959595959595959\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 118\n",
      "Number of words correctly disambiguated: 18\n",
      "Accuracy: 0.15254237288135594\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 99\n",
      "Number of words correctly disambiguated: 41\n",
      "Accuracy: 0.41414141414141414\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 123\n",
      "Number of words correctly disambiguated: 21\n",
      "Accuracy: 0.17073170731707318\n",
      "-------------------------------------------\n",
      "Iteraction number: 24\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 80\n",
      "Number of words correctly disambiguated: 46\n",
      "Accuracy: 0.575\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 98\n",
      "Number of words correctly disambiguated: 22\n",
      "Accuracy: 0.22448979591836735\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 80\n",
      "Number of words correctly disambiguated: 33\n",
      "Accuracy: 0.4125\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 113\n",
      "Number of words correctly disambiguated: 21\n",
      "Accuracy: 0.18584070796460178\n",
      "-------------------------------------------\n",
      "Iteraction number: 25\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 106\n",
      "Number of words correctly disambiguated: 59\n",
      "Accuracy: 0.5566037735849056\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 141\n",
      "Number of words correctly disambiguated: 22\n",
      "Accuracy: 0.15602836879432624\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 106\n",
      "Number of words correctly disambiguated: 40\n",
      "Accuracy: 0.37735849056603776\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 158\n",
      "Number of words correctly disambiguated: 18\n",
      "Accuracy: 0.11392405063291139\n",
      "-------------------------------------------\n",
      "Iteraction number: 26\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 90\n",
      "Number of words correctly disambiguated: 51\n",
      "Accuracy: 0.5666666666666667\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 113\n",
      "Number of words correctly disambiguated: 19\n",
      "Accuracy: 0.168141592920354\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 90\n",
      "Number of words correctly disambiguated: 37\n",
      "Accuracy: 0.4111111111111111\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 123\n",
      "Number of words correctly disambiguated: 21\n",
      "Accuracy: 0.17073170731707318\n",
      "-------------------------------------------\n",
      "Iteraction number: 27\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 144\n",
      "Number of words correctly disambiguated: 75\n",
      "Accuracy: 0.5208333333333334\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 141\n",
      "Number of words correctly disambiguated: 33\n",
      "Accuracy: 0.23404255319148937\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 144\n",
      "Number of words correctly disambiguated: 53\n",
      "Accuracy: 0.3680555555555556\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 136\n",
      "Number of words correctly disambiguated: 29\n",
      "Accuracy: 0.21323529411764705\n",
      "-------------------------------------------\n",
      "Iteraction number: 28\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 149\n",
      "Number of words correctly disambiguated: 81\n",
      "Accuracy: 0.5436241610738255\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 153\n",
      "Number of words correctly disambiguated: 28\n",
      "Accuracy: 0.1830065359477124\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 149\n",
      "Number of words correctly disambiguated: 55\n",
      "Accuracy: 0.3691275167785235\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 173\n",
      "Number of words correctly disambiguated: 32\n",
      "Accuracy: 0.18497109826589594\n",
      "-------------------------------------------\n",
      "Iteraction number: 29\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 111\n",
      "Number of words correctly disambiguated: 65\n",
      "Accuracy: 0.5855855855855856\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 119\n",
      "Number of words correctly disambiguated: 23\n",
      "Accuracy: 0.19327731092436976\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 111\n",
      "Number of words correctly disambiguated: 50\n",
      "Accuracy: 0.45045045045045046\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 137\n",
      "Number of words correctly disambiguated: 22\n",
      "Accuracy: 0.16058394160583941\n",
      "-------------------------------------------\n",
      "Iteraction number: 30\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 84\n",
      "Number of words correctly disambiguated: 51\n",
      "Accuracy: 0.6071428571428571\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 112\n",
      "Number of words correctly disambiguated: 15\n",
      "Accuracy: 0.13392857142857142\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 84\n",
      "Number of words correctly disambiguated: 36\n",
      "Accuracy: 0.42857142857142855\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 116\n",
      "Number of words correctly disambiguated: 16\n",
      "Accuracy: 0.13793103448275862\n",
      "-------------------------------------------\n",
      "Iteraction number: 31\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 83\n",
      "Number of words correctly disambiguated: 49\n",
      "Accuracy: 0.5903614457831325\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 108\n",
      "Number of words correctly disambiguated: 16\n",
      "Accuracy: 0.14814814814814814\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 83\n",
      "Number of words correctly disambiguated: 37\n",
      "Accuracy: 0.4457831325301205\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 114\n",
      "Number of words correctly disambiguated: 19\n",
      "Accuracy: 0.16666666666666666\n",
      "-------------------------------------------\n",
      "Iteraction number: 32\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 120\n",
      "Number of words correctly disambiguated: 79\n",
      "Accuracy: 0.6583333333333333\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 130\n",
      "Number of words correctly disambiguated: 31\n",
      "Accuracy: 0.23846153846153847\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 120\n",
      "Number of words correctly disambiguated: 51\n",
      "Accuracy: 0.425\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 140\n",
      "Number of words correctly disambiguated: 29\n",
      "Accuracy: 0.20714285714285716\n",
      "-------------------------------------------\n",
      "Iteraction number: 33\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 94\n",
      "Number of words correctly disambiguated: 52\n",
      "Accuracy: 0.5531914893617021\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 133\n",
      "Number of words correctly disambiguated: 19\n",
      "Accuracy: 0.14285714285714285\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 94\n",
      "Number of words correctly disambiguated: 40\n",
      "Accuracy: 0.425531914893617\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 137\n",
      "Number of words correctly disambiguated: 19\n",
      "Accuracy: 0.1386861313868613\n",
      "-------------------------------------------\n",
      "Iteraction number: 34\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 102\n",
      "Number of words correctly disambiguated: 62\n",
      "Accuracy: 0.6078431372549019\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 134\n",
      "Number of words correctly disambiguated: 26\n",
      "Accuracy: 0.19402985074626866\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 102\n",
      "Number of words correctly disambiguated: 40\n",
      "Accuracy: 0.39215686274509803\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 146\n",
      "Number of words correctly disambiguated: 25\n",
      "Accuracy: 0.17123287671232876\n",
      "-------------------------------------------\n",
      "Iteraction number: 35\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 93\n",
      "Number of words correctly disambiguated: 54\n",
      "Accuracy: 0.5806451612903226\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 136\n",
      "Number of words correctly disambiguated: 19\n",
      "Accuracy: 0.13970588235294118\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 93\n",
      "Number of words correctly disambiguated: 41\n",
      "Accuracy: 0.44086021505376344\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 151\n",
      "Number of words correctly disambiguated: 16\n",
      "Accuracy: 0.10596026490066225\n",
      "-------------------------------------------\n",
      "Iteraction number: 36\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 99\n",
      "Number of words correctly disambiguated: 63\n",
      "Accuracy: 0.6363636363636364\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 125\n",
      "Number of words correctly disambiguated: 25\n",
      "Accuracy: 0.2\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 99\n",
      "Number of words correctly disambiguated: 45\n",
      "Accuracy: 0.45454545454545453\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 127\n",
      "Number of words correctly disambiguated: 27\n",
      "Accuracy: 0.2125984251968504\n",
      "-------------------------------------------\n",
      "Iteraction number: 37\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 110\n",
      "Number of words correctly disambiguated: 68\n",
      "Accuracy: 0.6181818181818182\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 144\n",
      "Number of words correctly disambiguated: 24\n",
      "Accuracy: 0.16666666666666666\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 110\n",
      "Number of words correctly disambiguated: 42\n",
      "Accuracy: 0.38181818181818183\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 153\n",
      "Number of words correctly disambiguated: 19\n",
      "Accuracy: 0.12418300653594772\n",
      "-------------------------------------------\n",
      "Iteraction number: 38\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 106\n",
      "Number of words correctly disambiguated: 53\n",
      "Accuracy: 0.5\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 114\n",
      "Number of words correctly disambiguated: 29\n",
      "Accuracy: 0.2543859649122807\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 106\n",
      "Number of words correctly disambiguated: 36\n",
      "Accuracy: 0.33962264150943394\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 117\n",
      "Number of words correctly disambiguated: 20\n",
      "Accuracy: 0.17094017094017094\n",
      "-------------------------------------------\n",
      "Iteraction number: 39\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 142\n",
      "Number of words correctly disambiguated: 76\n",
      "Accuracy: 0.5352112676056338\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 160\n",
      "Number of words correctly disambiguated: 30\n",
      "Accuracy: 0.1875\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 142\n",
      "Number of words correctly disambiguated: 40\n",
      "Accuracy: 0.28169014084507044\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 145\n",
      "Number of words correctly disambiguated: 16\n",
      "Accuracy: 0.1103448275862069\n",
      "-------------------------------------------\n",
      "Iteraction number: 40\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 183\n",
      "Number of words correctly disambiguated: 107\n",
      "Accuracy: 0.5846994535519126\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 151\n",
      "Number of words correctly disambiguated: 32\n",
      "Accuracy: 0.2119205298013245\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 183\n",
      "Number of words correctly disambiguated: 78\n",
      "Accuracy: 0.4262295081967213\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 163\n",
      "Number of words correctly disambiguated: 37\n",
      "Accuracy: 0.22699386503067484\n",
      "-------------------------------------------\n",
      "Iteraction number: 41\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 88\n",
      "Number of words correctly disambiguated: 51\n",
      "Accuracy: 0.5795454545454546\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 122\n",
      "Number of words correctly disambiguated: 21\n",
      "Accuracy: 0.1721311475409836\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 88\n",
      "Number of words correctly disambiguated: 36\n",
      "Accuracy: 0.4090909090909091\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 124\n",
      "Number of words correctly disambiguated: 19\n",
      "Accuracy: 0.1532258064516129\n",
      "-------------------------------------------\n",
      "Iteraction number: 42\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 114\n",
      "Number of words correctly disambiguated: 64\n",
      "Accuracy: 0.5614035087719298\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 156\n",
      "Number of words correctly disambiguated: 34\n",
      "Accuracy: 0.21794871794871795\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 114\n",
      "Number of words correctly disambiguated: 46\n",
      "Accuracy: 0.40350877192982454\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 161\n",
      "Number of words correctly disambiguated: 30\n",
      "Accuracy: 0.18633540372670807\n",
      "-------------------------------------------\n",
      "Iteraction number: 43\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 90\n",
      "Number of words correctly disambiguated: 48\n",
      "Accuracy: 0.5333333333333333\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 136\n",
      "Number of words correctly disambiguated: 14\n",
      "Accuracy: 0.10294117647058823\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 90\n",
      "Number of words correctly disambiguated: 32\n",
      "Accuracy: 0.35555555555555557\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 150\n",
      "Number of words correctly disambiguated: 15\n",
      "Accuracy: 0.1\n",
      "-------------------------------------------\n",
      "Iteraction number: 44\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 110\n",
      "Number of words correctly disambiguated: 60\n",
      "Accuracy: 0.5454545454545454\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 130\n",
      "Number of words correctly disambiguated: 20\n",
      "Accuracy: 0.15384615384615385\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 110\n",
      "Number of words correctly disambiguated: 46\n",
      "Accuracy: 0.41818181818181815\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 141\n",
      "Number of words correctly disambiguated: 26\n",
      "Accuracy: 0.18439716312056736\n",
      "-------------------------------------------\n",
      "Iteraction number: 45\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 136\n",
      "Number of words correctly disambiguated: 79\n",
      "Accuracy: 0.5808823529411765\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 154\n",
      "Number of words correctly disambiguated: 38\n",
      "Accuracy: 0.24675324675324675\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 136\n",
      "Number of words correctly disambiguated: 57\n",
      "Accuracy: 0.41911764705882354\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 164\n",
      "Number of words correctly disambiguated: 36\n",
      "Accuracy: 0.21951219512195122\n",
      "-------------------------------------------\n",
      "Iteraction number: 46\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 120\n",
      "Number of words correctly disambiguated: 70\n",
      "Accuracy: 0.5833333333333334\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 144\n",
      "Number of words correctly disambiguated: 23\n",
      "Accuracy: 0.1597222222222222\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 120\n",
      "Number of words correctly disambiguated: 42\n",
      "Accuracy: 0.35\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 154\n",
      "Number of words correctly disambiguated: 16\n",
      "Accuracy: 0.1038961038961039\n",
      "-------------------------------------------\n",
      "Iteraction number: 47\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 112\n",
      "Number of words correctly disambiguated: 66\n",
      "Accuracy: 0.5892857142857143\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 140\n",
      "Number of words correctly disambiguated: 31\n",
      "Accuracy: 0.22142857142857142\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 112\n",
      "Number of words correctly disambiguated: 50\n",
      "Accuracy: 0.44642857142857145\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 154\n",
      "Number of words correctly disambiguated: 30\n",
      "Accuracy: 0.19480519480519481\n",
      "-------------------------------------------\n",
      "Iteraction number: 48\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 79\n",
      "Number of words correctly disambiguated: 44\n",
      "Accuracy: 0.5569620253164557\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 147\n",
      "Number of words correctly disambiguated: 17\n",
      "Accuracy: 0.11564625850340136\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 79\n",
      "Number of words correctly disambiguated: 27\n",
      "Accuracy: 0.34177215189873417\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 142\n",
      "Number of words correctly disambiguated: 16\n",
      "Accuracy: 0.11267605633802817\n",
      "-------------------------------------------\n",
      "Iteraction number: 49\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 92\n",
      "Number of words correctly disambiguated: 52\n",
      "Accuracy: 0.5652173913043478\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 118\n",
      "Number of words correctly disambiguated: 23\n",
      "Accuracy: 0.19491525423728814\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 92\n",
      "Number of words correctly disambiguated: 40\n",
      "Accuracy: 0.43478260869565216\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 122\n",
      "Number of words correctly disambiguated: 23\n",
      "Accuracy: 0.1885245901639344\n",
      "-------------------------------------------\n",
      "Iteraction number: 50\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus\n",
      "\n",
      "Total number of words to disambiguate: 106\n",
      "Number of words correctly disambiguated: 58\n",
      "Accuracy: 0.5471698113207547\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging\n",
      "\n",
      "Total number of words to disambiguate: 140\n",
      "Number of words correctly disambiguated: 22\n",
      "Accuracy: 0.15714285714285714\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the corpus without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 106\n",
      "Number of words correctly disambiguated: 35\n",
      "Accuracy: 0.330188679245283\n",
      "-------------------------------------------\n",
      "Sostantive words extracted from the POS Tagging without cleaning the sentences\n",
      "\n",
      "Total number of words to disambiguate: 147\n",
      "Number of words correctly disambiguated: 20\n",
      "Accuracy: 0.1360544217687075\n",
      "-------------------------------------------\n",
      "Mean accuracy from the corpus: 0.5729264508792974\n",
      "Mean accuracy from the POS Tagging: 0.18883166516382965\n",
      "Mean accuracy from the corpus without cleaning the sentences: 0.40657653785055325\n",
      "Mean accuracy from the POS Tagging without cleaning the sentences: 0.17032051869840514\n"
     ]
    }
   ],
   "source": [
    "accuracy_list_corpus = []\n",
    "accuracy_list_pos_tag = []\n",
    "accuracy_list_corpus_unclean = []\n",
    "accuracy_list_pos_tag_unclean = []\n",
    "\n",
    "for i in range(50):\n",
    "    # I select 50 random sentences in the range from 0 to the total number of tagged sentences\n",
    "    random_index = random.sample(range(0, tagged_sentences_semcor.size), 50)\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"Iteraction number:\", i + 1)\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"Sostantive words extracted from the corpus\\n\")\n",
    "    accuracy_list_corpus.append(get_accuracy_from_corpus(random_index, sentences_semcor, tagged_sentences_semcor, True))\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"Sostantive words extracted from the POS Tagging\\n\")\n",
    "    accuracy_list_pos_tag.append(get_accuracy_pos_tag(random_index, sentences_semcor, tagged_sentences_semcor, True))\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"Sostantive words extracted from the corpus without cleaning the sentences\\n\")\n",
    "    accuracy_list_corpus_unclean.append(get_accuracy_from_corpus(random_index, sentences_semcor, tagged_sentences_semcor, False))\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(\"Sostantive words extracted from the POS Tagging without cleaning the sentences\\n\")\n",
    "    accuracy_list_pos_tag_unclean.append(get_accuracy_pos_tag(random_index, sentences_semcor, tagged_sentences_semcor, False))\n",
    "\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"Mean accuracy from the corpus:\", np.mean(accuracy_list_corpus))\n",
    "print(\"Mean accuracy from the POS Tagging:\", np.mean(accuracy_list_pos_tag))\n",
    "print(\"Mean accuracy from the corpus without cleaning the sentences:\", np.mean(accuracy_list_corpus_unclean))\n",
    "print(\"Mean accuracy from the POS Tagging without cleaning the sentences:\", np.mean(accuracy_list_pos_tag_unclean))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
