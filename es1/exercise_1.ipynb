{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary imports and dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lores\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "from nltk.corpus.reader.wordnet import Synset\n",
    "nltk.download('wordnet')\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Human (mean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>sex</td>\n",
       "      <td>6.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tiger</td>\n",
       "      <td>cat</td>\n",
       "      <td>7.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tiger</td>\n",
       "      <td>tiger</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book</td>\n",
       "      <td>paper</td>\n",
       "      <td>7.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>computer</td>\n",
       "      <td>keyboard</td>\n",
       "      <td>7.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>shower</td>\n",
       "      <td>flood</td>\n",
       "      <td>6.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>weather</td>\n",
       "      <td>forecast</td>\n",
       "      <td>8.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>disaster</td>\n",
       "      <td>area</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>governor</td>\n",
       "      <td>office</td>\n",
       "      <td>6.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>architecture</td>\n",
       "      <td>century</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word 1    Word 2  Human (mean)\n",
       "0            love       sex          6.77\n",
       "1           tiger       cat          7.35\n",
       "2           tiger     tiger         10.00\n",
       "3            book     paper          7.46\n",
       "4        computer  keyboard          7.62\n",
       "..            ...       ...           ...\n",
       "348        shower     flood          6.03\n",
       "349       weather  forecast          8.34\n",
       "350      disaster      area          6.25\n",
       "351      governor    office          6.34\n",
       "352  architecture   century          3.78\n",
       "\n",
       "[353 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reading the file\n",
    "df = pd.read_csv('dataset\\combined.csv')\n",
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function to get the max depth of the synset\n",
    "\n",
    "def max_depth_synset(synset: Synset) -> int:\n",
    "    return max(len(path) for path in synset.hypernym_paths())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function to get the least common subsumer of two synsets\n",
    "\n",
    "def LCS(syn1: Synset, syn2: Synset) -> Synset | None:\n",
    "    path1 = syn1.hypernym_paths()\n",
    "    path2 = syn2.hypernym_paths()\n",
    "    result = []\n",
    "\n",
    "    # We loop through the paths of the first synset\n",
    "    for pat1 in path1:\n",
    "        x = pat1\n",
    "        x.reverse()\n",
    "        found = False\n",
    "        for syn in x:\n",
    "            if(not found):\n",
    "                # We loop through the paths of the second synset\n",
    "                for pat2 in path2:\n",
    "                    if(syn in pat2):\n",
    "                        result.append(syn)\n",
    "                        found = True\n",
    "                        break\n",
    "            else:\n",
    "                break\n",
    "    if not result:\n",
    "            return None\n",
    "    else:\n",
    "         max_depth = max(max_depth_synset(s) for s in result)\n",
    "         max_hypernym = max(s for s in result if max_depth_synset(s) == max_depth)\n",
    "         return max_hypernym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_len(syn1: Synset, syn2: Synset) -> int:\n",
    "    path1 = syn1.hypernym_paths()\n",
    "    path2 = syn2.hypernym_paths()\n",
    "    result_syn1 = []\n",
    "    result_syn2 = []\n",
    "\n",
    "    common_ancestor = LCS(syn1,syn2)\n",
    "\n",
    "    if(common_ancestor is None):\n",
    "        return None\n",
    "    else:\n",
    "        for pat1 in path1:\n",
    "            if(common_ancestor in pat1):\n",
    "                result_syn1.append(pat1.index(syn1)-pat1.index(common_ancestor))\n",
    "        for pat2 in path2:\n",
    "            if(common_ancestor in pat2):\n",
    "                result_syn2.append(pat2.index(syn2)-pat2.index(common_ancestor))\n",
    "        return min(result_syn1) + min(result_syn2)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_max = max(max(len(hyp_path) for hyp_path in ss.hypernym_paths()) for ss in wn.all_synsets())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wu Palmer\n",
    "\n",
    "$$ LCS(s1, s2) = {2 * depth(LCS(s1,s2)) \\over depth(s1) + depth(s2)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wu_palmer(syn1: Synset, syn2: Synset) -> float:\n",
    "    # We get all the synsets of the two words\n",
    "    depht1 = max_depth_synset(syn1)\n",
    "    depht2 = max_depth_synset(syn2)\n",
    "    # Finding the least common subsumer of the two synsets\n",
    "    common_ancestor = LCS(syn1,syn2)\n",
    "    if common_ancestor is None:\n",
    "        return 0\n",
    "    return 2 * max_depth_synset(common_ancestor) / ( depht1 + depht2 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortest Path\n",
    "\n",
    "$$ LCS(s1, s2) = 2 * depthMax - len(s1,s2) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path(syn1: Synset, syn2: Synset) -> int:\n",
    "    pat = path_len(syn1,syn2)\n",
    "    if pat is None:\n",
    "        return 0\n",
    "    elif (pat == 0):\n",
    "        return 2 * depth_max\n",
    "    elif (pat == depth_max):\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * depth_max - pat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leakcock & Chodorow\n",
    "\n",
    "$$ sim_LC(s1, s2) = -log(\\frac{len(s1,s2)}{2*depthMax}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leakcock_chodorow (syn1: Synset, syn2: Synset) -> float:\n",
    "    pat = path_len(syn1,syn2)\n",
    "    if pat is None:\n",
    "        return 0\n",
    "    elif (pat == 0):\n",
    "        return -math.log((1)/(2 * depth_max + 1))\n",
    "    else:\n",
    "        return -math.log((pat)/(2 * depth_max))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cycle for every synset of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synsets_cycle(word1: str, word2: str, metric: callable) -> float | str:\n",
    "    syn1 = wn.synsets(word1)\n",
    "    syn2 = wn.synsets(word2)\n",
    "    result = []\n",
    "    for s1 in syn1:\n",
    "        for s2 in syn2:\n",
    "            result.append(metric(s1,s2))\n",
    "    if not result:\n",
    "        return 0\n",
    "    else:\n",
    "        return max(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WU Palmer between dog and cat: 0.8571428571428571\n",
      "WU Palmer between stock and live: 0.2857142857142857\n",
      "Shortest Path between Jerusalem and Palestinian: 24\n",
      "Leakcock Chodorow between dog and cat: 2.3025850929940455\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "print(\"WU Palmer between dog and cat:\", synsets_cycle('dog','cat', wu_palmer))\n",
    "print(\"WU Palmer between stock and live:\", synsets_cycle('stock','live', wu_palmer))\n",
    "print(\"Shortest Path between Jerusalem and Palestinian:\", synsets_cycle('Jerusalem','Palestinian', shortest_path))\n",
    "print(\"Leakcock Chodorow between dog and cat:\", synsets_cycle('dog','cat', leakcock_chodorow))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over all pair of words in the dataset and i print the three similarity measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>Human (mean)</th>\n",
       "      <th>wu palmer</th>\n",
       "      <th>shortest path</th>\n",
       "      <th>leakcock chodorow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>sex</td>\n",
       "      <td>6.77</td>\n",
       "      <td>9.230769</td>\n",
       "      <td>9.75</td>\n",
       "      <td>9.933507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tiger</td>\n",
       "      <td>cat</td>\n",
       "      <td>7.35</td>\n",
       "      <td>9.655172</td>\n",
       "      <td>9.75</td>\n",
       "      <td>9.933507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tiger</td>\n",
       "      <td>tiger</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book</td>\n",
       "      <td>paper</td>\n",
       "      <td>7.46</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>9.50</td>\n",
       "      <td>8.066983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>computer</td>\n",
       "      <td>keyboard</td>\n",
       "      <td>7.62</td>\n",
       "      <td>8.235294</td>\n",
       "      <td>9.25</td>\n",
       "      <td>6.975136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>shower</td>\n",
       "      <td>flood</td>\n",
       "      <td>6.03</td>\n",
       "      <td>6.363636</td>\n",
       "      <td>9.00</td>\n",
       "      <td>6.200459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>weather</td>\n",
       "      <td>forecast</td>\n",
       "      <td>8.34</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>6.75</td>\n",
       "      <td>3.026547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>disaster</td>\n",
       "      <td>area</td>\n",
       "      <td>6.25</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.333935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>governor</td>\n",
       "      <td>office</td>\n",
       "      <td>6.34</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>7.75</td>\n",
       "      <td>4.016766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>architecture</td>\n",
       "      <td>century</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.076923</td>\n",
       "      <td>7.75</td>\n",
       "      <td>4.016766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word1     word2  Human (mean)  wu palmer  shortest path   \n",
       "0            love       sex          6.77   9.230769           9.75  \\\n",
       "1           tiger       cat          7.35   9.655172           9.75   \n",
       "2           tiger     tiger         10.00  10.000000          10.00   \n",
       "3            book     paper          7.46   8.750000           9.50   \n",
       "4        computer  keyboard          7.62   8.235294           9.25   \n",
       "..            ...       ...           ...        ...            ...   \n",
       "348        shower     flood          6.03   6.363636           9.00   \n",
       "349       weather  forecast          8.34   1.333333           6.75   \n",
       "350      disaster      area          6.25   5.000000           8.00   \n",
       "351      governor    office          6.34   5.263158           7.75   \n",
       "352  architecture   century          3.78   3.076923           7.75   \n",
       "\n",
       "     leakcock chodorow  \n",
       "0             9.933507  \n",
       "1             9.933507  \n",
       "2            10.000000  \n",
       "3             8.066983  \n",
       "4             6.975136  \n",
       "..                 ...  \n",
       "348           6.200459  \n",
       "349           3.026547  \n",
       "350           4.333935  \n",
       "351           4.016766  \n",
       "352           4.016766  \n",
       "\n",
       "[353 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through the dataset and calculate the similarity for each pair of words\n",
    "word1 = []\n",
    "word2 = []\n",
    "human_similarity = []\n",
    "wu_palmer_list = []\n",
    "shortest_path_list = []\n",
    "leakcock_chodorow_list = []\n",
    "for index, row in df.iterrows():\n",
    "    word1.append(row['Word 1'])\n",
    "    word2.append(row['Word 2'])\n",
    "    human_similarity.append(row['Human (mean)'])\n",
    "    wu_palmer_list.append(synsets_cycle(row['Word 1'], row['Word 2'], wu_palmer) * 10)\n",
    "    shortest_path_list.append( ( synsets_cycle(row['Word 1'], row['Word 2'], shortest_path) /40 ) * 10)\n",
    "    leakcock_chodorow_list.append( ( synsets_cycle(row['Word 1'], row['Word 2'], leakcock_chodorow) / math.log(41) ) * 10)\n",
    "df_metrics = pd.DataFrame({'word1': word1, 'word2': word2, \"Human (mean)\" : human_similarity,\"wu palmer\" : wu_palmer_list, \"shortest path\":shortest_path_list,\"leakcock chodorow\" : leakcock_chodorow_list})\n",
    "display(df_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
