{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizio 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessari e caricamento del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Human (mean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>sex</td>\n",
       "      <td>6.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tiger</td>\n",
       "      <td>cat</td>\n",
       "      <td>7.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tiger</td>\n",
       "      <td>tiger</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book</td>\n",
       "      <td>paper</td>\n",
       "      <td>7.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>computer</td>\n",
       "      <td>keyboard</td>\n",
       "      <td>7.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>shower</td>\n",
       "      <td>flood</td>\n",
       "      <td>6.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>weather</td>\n",
       "      <td>forecast</td>\n",
       "      <td>8.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>disaster</td>\n",
       "      <td>area</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>governor</td>\n",
       "      <td>office</td>\n",
       "      <td>6.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>architecture</td>\n",
       "      <td>century</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word 1    Word 2  Human (mean)\n",
       "0            love       sex          6.77\n",
       "1           tiger       cat          7.35\n",
       "2           tiger     tiger         10.00\n",
       "3            book     paper          7.46\n",
       "4        computer  keyboard          7.62\n",
       "..            ...       ...           ...\n",
       "348        shower     flood          6.03\n",
       "349       weather  forecast          8.34\n",
       "350      disaster      area          6.25\n",
       "351      governor    office          6.34\n",
       "352  architecture   century          3.78\n",
       "\n",
       "[353 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the file\n",
    "df = pd.read_csv('dataset\\combined.csv')\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wu & Palmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function to get the max depth of the synset\n",
    "\n",
    "def max_depth_2(synset):\n",
    "    return max(len(path) for path in synset.hypernym_paths())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function to get the least common subsumer of two synsets\n",
    "\n",
    "def LCS(syn1,syn2):\n",
    "    path1 = syn1.hypernym_paths()\n",
    "    path2 = syn2.hypernym_paths()\n",
    "    result = []\n",
    "\n",
    "    #se abbiamo piu path per il primo synset\n",
    "    if(len(path1) > 1):\n",
    "        # scorriamo un path alla volta \n",
    "        for pat1 in path1:\n",
    "            x = pat1\n",
    "            x.reverse()\n",
    "            for syn in x:\n",
    "                #se il secondo synset ha piu path devo scorrerli\n",
    "                for pat2 in path2:\n",
    "                    if(syn in pat2):\n",
    "                        result.append(syn)\n",
    "                        break     \n",
    "    else:#lunghezza di 1\n",
    "        pat1 = path1[0]\n",
    "        pat1.reverse()\n",
    "        for syn in pat1:\n",
    "            for pat2 in path2:\n",
    "                if(syn in pat2):\n",
    "                    result.append(syn) \n",
    "                    break\n",
    "    \n",
    "    max_depth = max(max_depth_2(s) for s in result)\n",
    "    max_hypernym = max(s for s in result if max_depth_2(s) == max_depth)\n",
    "    return max_hypernym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('carnivore.n.01')\n"
     ]
    }
   ],
   "source": [
    "print(LCS(wn.synset('cat.n.01'),wn.synset('dog.n.01')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('car.n.01')]\n",
      "12\n",
      "[Synset('person.n.01')]\n"
     ]
    }
   ],
   "source": [
    "synw1 = wn.synsets('car')\n",
    "max_depth = max(max_depth_2(s) for s in synw1)\n",
    "unsorted_lch = [s for s in synw1 if max_depth_2(s) == max_depth]\n",
    "print(unsorted_lch)\n",
    "for syn in unsorted_lch:\n",
    "    print(max_depth_2(syn))\n",
    "\n",
    "print(wn.synset('policeman.n.01').lowest_common_hypernyms(wn.synset('chef.n.01')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wu_palmer(word1,word2):\n",
    "    #prendiamo tutti i singificati delle parole\n",
    "    synw1 = wn.synsets(word1)\n",
    "    synw2 = wn.synsets(word2)\n",
    "    result = []\n",
    "\n",
    "    for syn1 in synw1:\n",
    "        #Profondita di syn1\n",
    "        depht1 = max_depth(syn1)\n",
    "        for syn2 in synw2:\n",
    "            #Profondita di syn2\n",
    "            depht2 = max_depth(syn2)# ritrovare l'antenato comune e calcolarne la profondita\n",
    "            \n",
    "#si fa la formula di dii wu_palmer\n",
    "           #si salva il risultato in una lista\n",
    "    #prendimao il valore max di similarita\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]\n",
      "[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('animal.n.01'), Synset('chordate.n.01'), Synset('vertebrate.n.01'), Synset('mammal.n.01'), Synset('placental.n.01'), Synset('carnivore.n.01'), Synset('canine.n.02'), Synset('dog.n.01')]\n",
      "[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('object.n.01'), Synset('whole.n.02'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('animal.n.01'), Synset('domestic_animal.n.01'), Synset('dog.n.01')]\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(wn.synset('dog.n.01').hypernyms())\n",
    "for a in wn.synset('dog.n.01').hypernym_paths():\n",
    "    print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
