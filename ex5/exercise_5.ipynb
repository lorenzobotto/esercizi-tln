{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk import pos_tag\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/blogtext.csv', encoding='utf-8', nrows=5000)\n",
    "df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_stem = SnowballStemmer('english')  \n",
    "\n",
    "def preprocess(sentence):\n",
    "    # Maintain only content words (nouns, verbs, adjectives, adverbs) of the sentence\n",
    "    sentence = pos_tag(sentence.split())\n",
    "    sentence = [word for word, tag in sentence if tag.startswith('NN') or tag.startswith('VB') or tag.startswith('JJ') or tag.startswith('RB')]\n",
    "    sentence = ' '.join(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence = sentence.replace('mail', '')\n",
    "    sentence = sentence.replace('urllink', '')\n",
    "    sentence = sentence.replace('nbsp', '')\n",
    "    sentence = sentence.replace('link', '')\n",
    "    sentence = sentence.replace('url', '')\n",
    "\n",
    "    # Removing unwanted characters\n",
    "    sentence = re.sub('[^A-Za-z0-9 ]+', \" \", sentence)\n",
    "\n",
    "    # Removing whitespaces\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    # Replacing more than 1 spaces with single space\n",
    "    sentence = sentence.replace(r\"\\s\\s+\", \" \")\n",
    "    \n",
    "    # Removing HTML tags\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    sentence = re.sub(cleanr, ' ', sentence)\n",
    "\n",
    "    # Removing punctuation\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Removing numbers\n",
    "    sentence = re.sub(r'\\d+', '', sentence)\n",
    "\n",
    "    # Removing stop words\n",
    "    words = [snow_stem.stem(word) for word in sentence.split() if word not in stop_words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_cleaned'] = df['text'].apply(preprocess)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I vectorize the documents using the TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=5000, min_df=10, token_pattern='[a-zA-Z0-9]{3,}')\n",
    "X = vectorizer.fit_transform(df['text_cleaned'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA for topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA for topic modelling\n",
    "lda = LatentDirichletAllocation(n_components=20,\n",
    "                                learning_decay=0.5,         \n",
    "                                max_iter=20,                \n",
    "                                learning_method='online',   \n",
    "                                random_state=42,            \n",
    "                                batch_size=128,            \n",
    "                                evaluate_every = -1,        \n",
    "                                n_jobs = -1) \n",
    "lda_output = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:  ['yeah', 'sigh', 'day', 'haha', 'wanna', 'write', 'hey']\n",
      "Topic 1:  ['republican', 'angi', 'bob', 'faith', 'pant', 'strong', 'boston']\n",
      "Topic 2:  ['peopl', 'point', 'year', 'believ', 'respons', 'issu', 'power']\n",
      "Topic 3:  ['cat', 'pillow', 'religion', 'protest', 'sex', 'nose', 'power']\n",
      "Topic 4:  ['use', 'wall', 'hous', 'build', 'valu', 'window', 'new']\n",
      "Topic 5:  ['song', 'name', 'band', 'play', 'nobodi', 'sing', 'listen']\n",
      "Topic 6:  ['eat', 'food', 'photo', 'bar', 'ice', 'candi', 'hee']\n",
      "Topic 7:  ['think', 'know', 'get', 'peopl', 'want', 'thing', 'make']\n",
      "Topic 8:  ['space', 'johnathan', 'hell', 'ridicul', 'heaven', 'career', 'statement']\n",
      "Topic 9:  ['look', 'car', 'see', 'eye', 'never', 'away', 'head']\n",
      "Topic 10:  ['got', 'get', 'day', 'went', 'night', 'back', 'good']\n",
      "Topic 11:  ['blog', 'post', 'com', 'friday', 'html', 'pic', 'check']\n",
      "Topic 12:  ['red', 'white', 'lie', 'bring', 'rain', 'love', 'beauti']\n",
      "Topic 13:  ['year', 'friend', 'love', 'life', 'live', 'know', 'famili']\n",
      "Topic 14:  ['game', 'play', 'good', 'guy', 'saturday', 'realli', 'weekend']\n",
      "Topic 15:  ['job', 'john', 'compani', 'yes', 'interview', 'employ', 'filipino']\n",
      "Topic 16:  ['bush', 'war', 'presid', 'american', 'said', 'nation', 'countri']\n",
      "Topic 17:  ['get', 'new', 'read', 'work', 'time', 'see', 'littl']\n",
      "Topic 18:  ['diva', 'dont', 'lol', 'love', 'cant', 'girl', 'cuz']\n",
      "Topic 19:  ['world', 'fear', 'understand', 'cultur', 'land', 'societi', 'question']\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "for index, component in enumerate(lda.components_):\n",
    "    zipped = zip(terms, component)\n",
    "    top_terms_key=sorted(zipped, key = lambda t: t[1], reverse=True)[:7]\n",
    "    top_terms_list=list(dict(top_terms_key).keys())\n",
    "    print(\"Topic \"+str(index)+\": \",top_terms_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.7, 'n_components': 5}\n",
      "Best Log Likelihood Score:  -464108.5695584055\n",
      "Model Perplexity:  1451.1484474595875\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV for hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "search_params = {'n_components': [5, 10, 15, 20, 25], 'learning_decay': [.5, .7, .9]}\n",
    "lda = LatentDirichletAllocation()\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "model.fit(X)\n",
    "\n",
    "# Best model\n",
    "best_lda_model = model.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([15.24805226, 13.92610822, 14.31365829, 14.22124124, 15.73362937,\n",
       "        13.85746818, 13.13738604, 13.58199811, 13.48960199, 14.74309187,\n",
       "        13.83305035, 13.03937597, 13.67054095, 15.59306135, 17.2330337 ]),\n",
       " 'std_fit_time': array([1.36910063, 1.08994086, 1.31470549, 1.42872672, 1.59831267,\n",
       "        1.05528171, 1.11257615, 1.20919761, 1.19643241, 1.3646233 ,\n",
       "        1.04241091, 1.29813436, 1.29953219, 1.84508111, 1.57063865]),\n",
       " 'mean_score_time': array([0.3147028 , 0.32480226, 0.35491614, 0.36134357, 0.41154037,\n",
       "        0.29681435, 0.31809549, 0.33589187, 0.36500115, 0.42325621,\n",
       "        0.29870787, 0.31541457, 0.36905551, 0.38660111, 0.47491136]),\n",
       " 'std_score_time': array([0.07394804, 0.0755045 , 0.08144761, 0.10150902, 0.12444253,\n",
       "        0.05833286, 0.08707437, 0.10360188, 0.10775972, 0.14053318,\n",
       "        0.06585443, 0.09941303, 0.09722951, 0.08550264, 0.16515361]),\n",
       " 'param_learning_decay': masked_array(data=[0.5, 0.5, 0.5, 0.5, 0.5, 0.7, 0.7, 0.7, 0.7, 0.7, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_components': masked_array(data=[5, 10, 15, 20, 25, 5, 10, 15, 20, 25, 5, 10, 15, 20,\n",
       "                    25],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learning_decay': 0.5, 'n_components': 5},\n",
       "  {'learning_decay': 0.5, 'n_components': 10},\n",
       "  {'learning_decay': 0.5, 'n_components': 15},\n",
       "  {'learning_decay': 0.5, 'n_components': 20},\n",
       "  {'learning_decay': 0.5, 'n_components': 25},\n",
       "  {'learning_decay': 0.7, 'n_components': 5},\n",
       "  {'learning_decay': 0.7, 'n_components': 10},\n",
       "  {'learning_decay': 0.7, 'n_components': 15},\n",
       "  {'learning_decay': 0.7, 'n_components': 20},\n",
       "  {'learning_decay': 0.7, 'n_components': 25},\n",
       "  {'learning_decay': 0.9, 'n_components': 5},\n",
       "  {'learning_decay': 0.9, 'n_components': 10},\n",
       "  {'learning_decay': 0.9, 'n_components': 15},\n",
       "  {'learning_decay': 0.9, 'n_components': 20},\n",
       "  {'learning_decay': 0.9, 'n_components': 25}],\n",
       " 'split0_test_score': array([-818426.26775538, -841063.06016287, -857447.42739498,\n",
       "        -873439.82990945, -887376.77691952, -817840.71560389,\n",
       "        -839854.83542874, -859320.93367342, -873515.85617444,\n",
       "        -889875.0439236 , -819294.86217851, -840025.24388844,\n",
       "        -860358.39568191, -873290.18055849, -888069.91441934]),\n",
       " 'split1_test_score': array([-398574.44685633, -418461.68927697, -432319.25132033,\n",
       "        -448328.13479233, -462712.88031247, -397861.85507033,\n",
       "        -415588.19040908, -432633.62221497, -448840.73561483,\n",
       "        -464612.53790181, -398937.97267815, -416104.26547263,\n",
       "        -435059.06447594, -448985.39750846, -462606.29836405]),\n",
       " 'split2_test_score': array([-209793.15620992, -226918.92870552, -244118.37005645,\n",
       "        -256971.70197987, -273961.28606393, -210023.17064276,\n",
       "        -229361.4597545 , -245171.75538252, -259344.0290877 ,\n",
       "        -271277.49321249, -209571.96309752, -229395.4709366 ,\n",
       "        -245772.97760105, -256410.17572475, -273890.40397289]),\n",
       " 'split3_test_score': array([-369914.21041249, -387842.03481576, -407196.1167301 ,\n",
       "        -419880.62516821, -435077.54340616, -369853.27935544,\n",
       "        -388318.07966995, -404550.93887979, -421988.38355703,\n",
       "        -436551.81195961, -369684.05900181, -389593.01956773,\n",
       "        -404969.14551163, -420404.78519808, -436022.51478705]),\n",
       " 'split4_test_score': array([-524659.87705053, -545994.00509762, -560905.73222333,\n",
       "        -574996.52454098, -587287.55248355, -524963.82711961,\n",
       "        -544750.46075883, -561170.32798538, -574365.36388626,\n",
       "        -590108.74980795, -524240.31789973, -543064.92393243,\n",
       "        -562407.4475103 , -575081.74204161, -586119.54933663]),\n",
       " 'mean_test_score': array([-464273.59165693, -484055.94361175, -500397.37954504,\n",
       "        -514723.36327817, -529283.20783712, -464108.56955841,\n",
       "        -483574.60520422, -500569.51562722, -515610.87366405,\n",
       "        -530485.12736109, -464345.83497114, -483636.58475957,\n",
       "        -501713.40615617, -514834.45620628, -529341.73617599]),\n",
       " 'std_test_score': array([203494.9551871 , 205411.57299977, 205010.26074361, 205985.31386531,\n",
       "        204983.46649015, 203303.64992917, 204449.68541168, 205639.44516603,\n",
       "        205155.64054888, 206430.3039119 , 203825.87032544, 204248.84533956,\n",
       "        205726.88272041, 205988.54910499, 205098.56401156]),\n",
       " 'rank_test_score': array([ 2,  6,  7, 10, 13,  1,  4,  8, 12, 15,  3,  5,  9, 11, 14])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_fit_time\n",
      "std_fit_time\n",
      "mean_score_time\n",
      "std_score_time\n",
      "param_learning_decay\n",
      "param_n_components\n",
      "params\n",
      "split0_test_score\n",
      "split1_test_score\n",
      "split2_test_score\n",
      "split3_test_score\n",
      "split4_test_score\n",
      "mean_test_score\n",
      "std_test_score\n",
      "rank_test_score\n"
     ]
    }
   ],
   "source": [
    "for gscore in model.cv_results_:\n",
    "    print(gscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Get Log Likelyhoods from Grid Search Output\u001b[39;00m\n\u001b[0;32m      2\u001b[0m n_topics \u001b[39m=\u001b[39m [\u001b[39m5\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m15\u001b[39m, \u001b[39m20\u001b[39m, \u001b[39m25\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m log_likelyhoods_5 \u001b[39m=\u001b[39m [\u001b[39mround\u001b[39;49m(gscore\u001b[39m.\u001b[39;49mmean_validation_score) \u001b[39mfor\u001b[39;49;00m gscore \u001b[39min\u001b[39;49;00m model\u001b[39m.\u001b[39;49mcv_results_ \u001b[39mif\u001b[39;49;00m model\u001b[39m.\u001b[39;49mcv_results_\u001b[39m.\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mlearning_decay\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m==\u001b[39;49m\u001b[39m0.5\u001b[39;49m]\n\u001b[0;32m      4\u001b[0m log_likelyhoods_7 \u001b[39m=\u001b[39m [\u001b[39mround\u001b[39m(gscore\u001b[39m.\u001b[39mmean_validation_score) \u001b[39mfor\u001b[39;00m gscore \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mcv_results_ \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mcv_results_\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mlearning_decay\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m0.7\u001b[39m]\n\u001b[0;32m      5\u001b[0m log_likelyhoods_9 \u001b[39m=\u001b[39m [\u001b[39mround\u001b[39m(gscore\u001b[39m.\u001b[39mmean_validation_score) \u001b[39mfor\u001b[39;00m gscore \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mcv_results_ \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mcv_results_\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mlearning_decay\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m0.9\u001b[39m]\n",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Get Log Likelyhoods from Grid Search Output\u001b[39;00m\n\u001b[0;32m      2\u001b[0m n_topics \u001b[39m=\u001b[39m [\u001b[39m5\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m15\u001b[39m, \u001b[39m20\u001b[39m, \u001b[39m25\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m log_likelyhoods_5 \u001b[39m=\u001b[39m [\u001b[39mround\u001b[39m(gscore\u001b[39m.\u001b[39mmean_validation_score) \u001b[39mfor\u001b[39;00m gscore \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mcv_results_ \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39;49mcv_results_\u001b[39m.\u001b[39;49mparams[\u001b[39m'\u001b[39m\u001b[39mlearning_decay\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m0.5\u001b[39m]\n\u001b[0;32m      4\u001b[0m log_likelyhoods_7 \u001b[39m=\u001b[39m [\u001b[39mround\u001b[39m(gscore\u001b[39m.\u001b[39mmean_validation_score) \u001b[39mfor\u001b[39;00m gscore \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mcv_results_ \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mcv_results_\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mlearning_decay\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m0.7\u001b[39m]\n\u001b[0;32m      5\u001b[0m log_likelyhoods_9 \u001b[39m=\u001b[39m [\u001b[39mround\u001b[39m(gscore\u001b[39m.\u001b[39mmean_validation_score) \u001b[39mfor\u001b[39;00m gscore \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mcv_results_ \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mcv_results_\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mlearning_decay\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m0.9\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'params'"
     ]
    }
   ],
   "source": [
    "# Get Log Likelyhoods from Grid Search Output\n",
    "n_topics = [5, 10, 15, 20, 25]\n",
    "log_likelyhoods_5 = [round(gscore.mean_validation_score) for gscore in model.cv_results_ if model.cv_results_.params['learning_decay']==0.5]\n",
    "log_likelyhoods_7 = [round(gscore.mean_validation_score) for gscore in model.cv_results_ if model.cv_results_.params['learning_decay']==0.7]\n",
    "log_likelyhoods_9 = [round(gscore.mean_validation_score) for gscore in model.cv_results_ if model.cv_results_.params['learning_decay']==0.9]\n",
    "\n",
    "# Show graph\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(n_topics, log_likelyhoods_5, label='0.5')\n",
    "plt.plot(n_topics, log_likelyhoods_7, label='0.7')\n",
    "plt.plot(n_topics, log_likelyhoods_9, label='0.9')\n",
    "plt.title(\"Choosing Optimal LDA Model\")\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Log Likelyhood Scores\")\n",
    "plt.legend(title='Learning decay', loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
