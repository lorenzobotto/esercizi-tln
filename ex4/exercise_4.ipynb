{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 - Part A"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from nltk import tokenize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "with open(\"data/data.txt\", \"r\", encoding='utf8') as f:\n",
    "    lines = f.read().replace(\"\\n\", \" \")\n",
    "    sentences = tokenize.sent_tokenize(lines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the embeddings of the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert Embeddings for each sentence\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "bert_embeddings_definition = model.encode(sentences, convert_to_tensor=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the occurrence of each word in every sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating three random numbers with a minimum spacing between them\n",
    "\n",
    "def spreadRandom(theRange, howMany, minSpacing):\n",
    "    while True:\n",
    "        candidate = sorted([random.randint(*theRange) for _ in range(howMany)])\n",
    "        minDiff = min([ candidate[i+1]-candidate[i] for i, _ in enumerate(candidate[:-1])])\n",
    "        if minDiff >= minSpacing:\n",
    "            return candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "def get_bert_embedding(sentence: str) -> np.ndarray:\n",
    "    bert_embeddings_definition = model.encode(sentence, convert_to_tensor=True)\n",
    "    return bert_embeddings_definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(blocks: list) -> list:\n",
    "    blocks_embeddings = []\n",
    "    for i in range(len(blocks)):\n",
    "        block_embedding = model.encode(blocks[i], convert_to_tensor=True)\n",
    "        blocks_embeddings.append(util.torch.mean(util.cos_sim(block_embedding, block_embedding)).item())\n",
    "\n",
    "    return blocks_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity_between_blocks(blocks: list) -> list:\n",
    "    blocks_embeddings = []\n",
    "    for i in range(len(blocks)):\n",
    "        block_embeddings = []\n",
    "        for sentence in blocks[i]:\n",
    "            block_embedding = model.encode(sentence, convert_to_tensor=True)\n",
    "            block_embeddings.append(block_embedding)\n",
    "        blocks_embeddings.append(np.sum(block_embeddings))\n",
    "    blocks_embeddings[0] = util.cos_sim(blocks_embeddings[0], blocks_embeddings[1])\n",
    "    blocks_embeddings[1] = util.cos_sim(blocks_embeddings[1], blocks_embeddings[2])\n",
    "\n",
    "    return blocks_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the text into 3 blocks of random dimension\n",
    "blocks_index = spreadRandom([5, len(sentences) - 5], 2, 10)\n",
    "blocks = [sentences[0:blocks_index[0]], sentences[blocks_index[0]:blocks_index[1]], sentences[blocks_index[1]:]]\n",
    "\n",
    "changed = True\n",
    "\n",
    "while changed:\n",
    "    # Calculate the cosine similarity inside each block\n",
    "    changed = False\n",
    "    blocks_similarity = calculate_cosine_similarity(blocks)\n",
    "    # blocks_similarity_between = calculate_cosine_similarity_between_blocks(blocks)\n",
    "\n",
    "    # Calculate the cosine similarity changing the blocks\n",
    "    new_blocks_index_add = [x + 1 if x + 1 < len(sentences) else x for x in blocks_index]\n",
    "    new_blocks_add = [sentences[0:new_blocks_index_add[0]], sentences[new_blocks_index_add[0]:new_blocks_index_add[1]], sentences[new_blocks_index_add[1]:]]\n",
    "\n",
    "    new_blocks_index_sub = [x - 1 if x - 1 < len(sentences) else x for x in blocks_index]\n",
    "    new_blocks_sub = [sentences[0:new_blocks_index_sub[0]], sentences[new_blocks_index_sub[0]:new_blocks_index_sub[1]], sentences[new_blocks_index_sub[1]:]]\n",
    "\n",
    "    # Calculate the cosine similarity inside each block\n",
    "    new_blocks_similarity_add = calculate_cosine_similarity(new_blocks_add)\n",
    "    new_blocks_similarity_sub = calculate_cosine_similarity(new_blocks_sub)\n",
    "\n",
    "    # # # Calculate the cosine similarity between adjacent blocks\n",
    "    # new_blocks_similarity_between_add = calculate_cosine_similarity_between_blocks(new_blocks_add)\n",
    "    # new_blocks_similarity_between_sub = calculate_cosine_similarity_between_blocks(new_blocks_sub)\n",
    "\n",
    "    # Change the blocks if the cosine similarity is higher valutating the 3 blocks\n",
    "    if new_blocks_similarity_add[0] > blocks_similarity[0] \\\n",
    "       and (new_blocks_similarity_add[0] - blocks_similarity[0]) > (new_blocks_similarity_sub[0] - blocks_similarity[0]):\n",
    "        blocks_index[0] = blocks_index[0] + 1\n",
    "        blocks[0] = sentences[0:blocks_index[0]]\n",
    "        changed = True\n",
    "        print(\"Changed Block 1 (+1): \", blocks_index)\n",
    "        continue\n",
    "    elif new_blocks_similarity_sub[0] > blocks_similarity[0] \\\n",
    "         and (new_blocks_similarity_sub[0] - blocks_similarity[0]) > (new_blocks_similarity_add[0] - blocks_similarity[0]):         \n",
    "        blocks_index[0] = blocks_index[0] - 1\n",
    "        blocks[0] = sentences[0:blocks_index[0]]\n",
    "        changed = True\n",
    "        print(\"Changed Block 1 (-1): \", blocks_index)\n",
    "        continue\n",
    "    if new_blocks_similarity_add[1] > blocks_similarity[1] \\\n",
    "       and (new_blocks_similarity_add[1] - blocks_similarity[1]) > (new_blocks_similarity_sub[1] - blocks_similarity[1]):\n",
    "        blocks_index[1] = blocks_index[1] + 1\n",
    "        blocks[1] = sentences[blocks_index[0]:blocks_index[1]]\n",
    "        changed = True\n",
    "        print(\"Changed Block 2 (+1): \", blocks_index)\n",
    "        continue\n",
    "    elif new_blocks_similarity_sub[1] > blocks_similarity[1] \\\n",
    "         and (new_blocks_similarity_sub[1] - blocks_similarity[1]) > (new_blocks_similarity_add[1] - blocks_similarity[1]):\n",
    "        blocks_index[1] = blocks_index[1] - 1\n",
    "        blocks[1] = sentences[blocks_index[0]:blocks_index[1]]\n",
    "        changed = True\n",
    "        print(\"Changed Block 2 (-1): \", blocks_index)\n",
    "        continue\n",
    "\n",
    "print(\"Blocks Index: \", blocks_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the paragraphs\n",
    "for sentence in sentences[0:blocks_index[0]]:\n",
    "    print(sentence)\n",
    "print(\"\\n\\n\")\n",
    "for sentence in sentences[blocks_index[0]:blocks_index[1]]:\n",
    "    print(sentence)\n",
    "print(\"\\n\\n\")\n",
    "for sentence in sentences[blocks_index[1]:]:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[23]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
