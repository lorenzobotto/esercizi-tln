{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package framenet_v17 to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import framenet as fn\n",
    "from nltk.corpus.reader.wordnet import Synset\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('framenet_v17')\n",
    "nltk.download('wordnet')\n",
    "import hashlib\n",
    "import re\n",
    "from random import randint\n",
    "from random import seed\n",
    "from nltk.corpus import wordnet as wn\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First part"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the frames from name and surname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames_IDs():\n",
    "    return [f.ID for f in fn.frames()]   \n",
    "\n",
    "def getFrameSetForStudent(surname, list_len=5):\n",
    "    nof_frames = len(fn.frames())\n",
    "    base_idx = (abs(int(hashlib.sha512(surname.encode('utf-8')).hexdigest(), 16)) % nof_frames)\n",
    "    print('\\nStudent: ' + surname)\n",
    "    framenet_IDs = get_frames_IDs()\n",
    "    i = 0\n",
    "    offset = 0 \n",
    "    seed(1)\n",
    "    frames_extracted = {}\n",
    "    while i < list_len:\n",
    "        fID = framenet_IDs[(base_idx+offset)%nof_frames]\n",
    "        f = fn.frame(fID)\n",
    "        fNAME = f.name\n",
    "        frames_extracted[fID] = fNAME\n",
    "        print('\\tID: {a:4d}\\tFrame: {framename}'.format(a=fID, framename=fNAME))\n",
    "        offset = randint(0, nof_frames)\n",
    "        i += 1\n",
    "    return frames_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Student: Lorenzo Botto\n",
      "\tID: 1882\tFrame: Shopping\n",
      "\tID: 1148\tFrame: Attributed_information\n",
      "\tID: 2231\tFrame: Response_scenario\n",
      "\tID: 2191\tFrame: Turning_out\n",
      "\tID:  380\tFrame: Custom\n",
      "\n",
      "Student: Gabriele Naretto\n",
      "\tID: 2018\tFrame: Collocation_image_schema\n",
      "\tID: 1497\tFrame: Giving_in\n",
      "\tID:  334\tFrame: Cause_temperature_change\n",
      "\tID: 1211\tFrame: Dressing\n",
      "\tID: 1147\tFrame: Ordinal_numbers\n"
     ]
    }
   ],
   "source": [
    "# I extract the frames for Lorenzo Botto and Gabriele Naretto and I merge them in a single dictionary\n",
    "\n",
    "frames_student1 = getFrameSetForStudent('Lorenzo Botto')\n",
    "frames_student2 = getFrameSetForStudent('Gabriele Naretto')\n",
    "frames_extracted = { \"lorenzo\":frames_student1} | {\"gabriele\" : frames_student2}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### execution of the lesk algoritm for found the best synset in wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I clean the sentences removing the punctuation and the stop words\n",
    "\n",
    "def clean_sentence(sentence: str | list) -> list:\n",
    "    sentence_without_puntuaction = re.sub(r'[^\\w\\s]', '', str(sentence)).strip()\n",
    "    word_tokens = word_tokenize(sentence_without_puntuaction)\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lesk(word: str, sentence: list, clean: bool) -> Synset:\n",
    "    synsets = wn.synsets(word)\n",
    "    if not synsets:\n",
    "        return None\n",
    "    best_sense = synsets[0]\n",
    "    max_overlap = 0\n",
    "    for synset in synsets:\n",
    "        overlap = 0\n",
    "        # Cleaning example in wordnet \n",
    "        for definition_word in clean_sentence(synset.definition()) if clean else synset.definition().split():\n",
    "            if definition_word in sentence:\n",
    "                overlap += 1\n",
    "        for example_word in clean_sentence(synset.examples()) if clean else synset.examples():\n",
    "            if clean:\n",
    "                if example_word in sentence:\n",
    "                    overlap += 1\n",
    "            else:\n",
    "                for example_word in example_word.split():\n",
    "                    if example_word in sentence:\n",
    "                        overlap += 1\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            best_sense = synset\n",
    "        \n",
    "    return best_sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name of the student lorenzo\n",
      "-----------------------------------\n",
      "lesk algoritm on Frame name\n",
      "Shopping\n",
      "A Shopper looks for Goods in order to purchase them.  'She shopped for a new hat.'\n",
      "Synset('shop.v.03')\n",
      "Lexical units in the frame\n",
      "['Shopper', 'Ground', 'Goods', 'Manner', 'Means', 'Outcome', 'Place', 'Time', 'Purpose', 'Degree', 'Depictive', 'Co-participant']\n",
      "Synset('shopper.n.02')\n",
      "Synset('ground.v.07')\n",
      "Synset('good.n.01')\n",
      "Synset('manner.n.01')\n",
      "Synset('mean.n.01')\n",
      "Synset('result.n.03')\n",
      "Synset('topographic_point.n.01')\n",
      "Synset('time.n.01')\n",
      "Synset('purpose.n.01')\n",
      "Synset('degree.n.01')\n",
      "Synset('delineative.s.01')\n",
      "None\n",
      "-----------------------------------\n",
      "lesk algoritm on Frame name\n",
      "Attributed_information\n",
      "A Proposition is attributed to a Speaker or a Text.  'According to the Press Trust of India in an article published on its Web site Thursday, the woman has been identified as 31-year-old Aafia Siddiqui, who was being sought by U.S. officials last week along with two other men, including one whose last known address was in Miramar, Fla.'  ' In addition, according to Section I3.5b, the spacing of stud shear connectors along the length of a supporting beam shall not exceed 36?. '  'According to the Pope, Muslims believe in the same God and according to Jesus, Muslims are the greatest in Heaven.'\n",
      "Synset('impute.v.01')\n",
      "Lexical units in the frame\n",
      "['Proposition', 'Speaker', 'Text']\n",
      "Synset('proposition.n.01')\n",
      "Synset('speaker.n.03')\n",
      "Synset('text.n.01')\n",
      "-----------------------------------\n",
      "lesk algoritm on Frame name\n",
      "Response_scenario\n",
      "A Trigger elicits a Response by some Responding_entity or an Agent.  \n",
      "Synset('response.n.01')\n",
      "Lexical units in the frame\n",
      "['Responding_entity', 'Trigger', 'Response', 'Agent', 'Manner', 'Place', 'Purpose', 'Time']\n",
      "Synset('react.v.01')\n",
      "Synset('trigger.v.02')\n",
      "Synset('response.n.01')\n",
      "Synset('agentive_role.n.01')\n",
      "Synset('manner.n.01')\n",
      "Synset('topographic_point.n.01')\n",
      "Synset('purpose.n.01')\n",
      "Synset('time.n.01')\n",
      "-----------------------------------\n",
      "lesk algoritm on Frame name\n",
      "Turning_out\n",
      "A State_of_affairs turns out to be true in someone's knowledge of the world. This may be recognized with evidence or in certain circumstances. The cognizer whose beliefs are affected is not expressed.  'Hybrid grass may prove to be a valuable fuel source.'\n",
      "Synset('turn.v.19')\n",
      "Lexical units in the frame\n",
      "['State_of_affairs', 'Time']\n",
      "Synset('state.n.01')\n",
      "Synset('clock_time.n.01')\n",
      "-----------------------------------\n",
      "lesk algoritm on Frame name\n",
      "Custom\n",
      "A Behavior is classified as entrenched for a Protagonist or a Society. The Behavior may be associated with a particular Domain of experience and described with a Descriptor. This indicates that the Behavior is commonly performed by the Protagonist or members of the Society.  'It is an old  Jewish custom. ' 'He was unaware of the Japanese custom of waiting until the giver had departed. ' ' The ancient tradition of swan-upping has been taking place on the river Thames.' 'Smithers thought that hunting lions was just another native custom ' 'Marko showed great respect for the social customs of his people.' ' When I reply to debates , it is my custom to have heard all the speeches that have been made. '\n",
      "Synset('custom.n.04')\n",
      "Lexical units in the frame\n",
      "['Behavior', 'Protagonist', 'Domain', 'Descriptor', 'Place', 'Society']\n",
      "Synset('demeanor.n.01')\n",
      "Synset('supporter.n.01')\n",
      "Synset('sphere.n.01')\n",
      "Synset('form.n.01')\n",
      "Synset('place.n.03')\n",
      "Synset('club.n.02')\n",
      "name of the student gabriele\n",
      "-----------------------------------\n",
      "lesk algoritm on Frame name\n",
      "Collocation_image_schema\n",
      "A Profiled_region is specified as entirely or largely coinciding with that of a Ground.\n",
      "Synset('collocation.n.01')\n",
      "Lexical units in the frame\n",
      "['Profiled_region', 'Ground']\n",
      "Synset('profile.v.01')\n",
      "Synset('earth.n.02')\n",
      "-----------------------------------\n",
      "lesk algoritm on Frame name\n",
      "Giving_in\n",
      "A Capitulator who has been opposing a Force, which is typically exerted by a Compeller, ceases opposing that Force. As a result, the Force runs its course and an Issue is resolved against the interests of the Capitulator.   'Accordingly, there is no basis to conclude that Tazewell acquiesced in the rule against claim-splitting.' 'Accordingly, there is no basis to conclude that Tazewell acquiesced in the rule against claim-splitting.'   'My uncle continued trying to placate Nuayman until the latter relented. DNI DNI'   ' Genesis acquiesced to doing a short Q and A session. DNI'  'The government would not yield to pressure , the spokeswoman promised . DNI'  \n",
      "Synset('give.v.43')\n",
      "Lexical units in the frame\n",
      "['Capitulator', 'Issue', 'Compeller', 'Time', 'Explanation', 'Force', 'Place', 'Purpose', 'Manner', 'Degree', 'Resultant_action']\n",
      "None\n",
      "Synset('issue.n.05')\n",
      "None\n",
      "Synset('time.n.04')\n",
      "Synset('explanation.n.01')\n",
      "Synset('force.n.03')\n",
      "Synset('stead.n.01')\n",
      "Synset('purpose.n.01')\n",
      "Synset('manner.n.03')\n",
      "Synset('academic_degree.n.01')\n",
      "Synset('resultant.n.01')\n",
      "-----------------------------------\n",
      "lesk algoritm on Frame name\n",
      "Cause_temperature_change\n",
      "In this frame, an Agent changes the temperature of an Item.  A Temperature_goal can specify the desired temperature.  A Temperature_change can also be indicated.  The Temperature_start indicates the initial temperature.  'Margaret Anne chilled the salad to 30 degrees.' 'Heat the water 30 degrees.'\n",
      "Synset('cause.n.01')\n",
      "Lexical units in the frame\n",
      "['Agent', 'Instrument', 'Item', 'Temperature_goal', 'Temperature_change', 'Temperature_start', 'Manner', 'Means', 'Place', 'Purpose', 'Time', 'Result', 'Cause', 'Duration', 'Subregion', 'Container', 'Depictive', 'Hot_Cold_source', 'Circumstances', 'Degree']\n",
      "Synset('agent.n.01')\n",
      "Synset('instrumental_role.n.01')\n",
      "Synset('token.n.01')\n",
      "Synset('temperature.n.01')\n",
      "Synset('temperature.n.01')\n",
      "Synset('temperature.n.01')\n",
      "Synset('manner.n.01')\n",
      "Synset('mean.n.01')\n",
      "Synset('stead.n.01')\n",
      "Synset('purpose.n.01')\n",
      "Synset('time.n.04')\n",
      "Synset('leave.v.07')\n",
      "Synset('cause.n.01')\n",
      "Synset('duration.n.01')\n",
      "None\n",
      "Synset('container.n.01')\n",
      "Synset('delineative.s.01')\n",
      "Synset('hot.a.01')\n",
      "Synset('fortune.n.04')\n",
      "Synset('degree.n.07')\n",
      "-----------------------------------\n",
      "lesk algoritm on Frame name\n",
      "Dressing\n",
      "A Wearer puts on an item of Clothing, which then occupies the Body_location.  'You didn't have to dress like a pirate to impress me. INI' 'He put on his thickest pair of gloves and then went back out to see if he could move them now. INI' 'Jack put on his watch - on his right wrist, and checked the time.'\n",
      "Synset('dress.v.01')\n",
      "Lexical units in the frame\n",
      "['Wearer', 'Clothing', 'Body_location', 'Manner', 'Depictive', 'Means', 'Result', 'Duration', 'Place', 'Explanation', 'Time', 'Purpose']\n",
      "Synset('wearer.n.01')\n",
      "Synset('dress.v.02')\n",
      "None\n",
      "Synset('manner.n.01')\n",
      "Synset('delineative.s.01')\n",
      "Synset('mean.n.01')\n",
      "Synset('solution.n.02')\n",
      "Synset('duration.n.03')\n",
      "Synset('position.n.01')\n",
      "Synset('explanation.n.01')\n",
      "Synset('time.n.02')\n",
      "Synset('purpose.n.01')\n",
      "-----------------------------------\n",
      "lesk algoritm on Frame name\n",
      "Ordinal_numbers\n",
      "An Item is picked out either by the order in which the members of a set would be encountered by an implicit cognizer, or by the order in which the members of a set participate in an event or state which serves as the Basis_of_order. The former case usually involves a Starting_point for going through the set, while the latter involves a Basis_of_order, which is normally an event that the Item along with other members of its Comparison_set has participated in.  Note that Item should be annotated on a second layer, except in cases when the noun structure the ordinal participates in is predicative.  'The first car from the left is a Magosix.' 'The first car from the left is a Magosix.' 'Barney was only the second Asian student at my college.' 'Felix was the first of my cats to realize that human food was tastier.' 'Felix was the first of my cats to realize that human food was tastier.'\n",
      "Synset('ordinal.a.02')\n",
      "Lexical units in the frame\n",
      "['Type', 'Starting_point', 'Basis_of_order', 'Item', 'Comparison_set']\n",
      "Synset('character.n.05')\n",
      "Synset('start.v.09')\n",
      "Synset('basis.n.03')\n",
      "Synset('item.n.01')\n",
      "Synset('comparison.n.01')\n"
     ]
    }
   ],
   "source": [
    "for name in frames_extracted:\n",
    "    print(\"name of the student\",name)\n",
    "    for frames_id in frames_extracted[name]:\n",
    "        print(\"-----------------------------------\")\n",
    "        print(\"lesk algoritm on Frame name\")\n",
    "        #for the frame name we use lesk algoritm for return the best sense in wordnet\n",
    "        print(fn.frame(frames_id).name)\n",
    "        print(fn.frame(frames_id).definition)\n",
    "        if(\"_\" in fn.frame(frames_id).name):\n",
    "            print(lesk(fn.frame(frames_id).name.split(\"_\")[0],fn.frame(frames_id).definition,True))\n",
    "        else:\n",
    "            print(lesk(fn.frame(frames_id).name,fn.frame(frames_id).definition,True))\n",
    "\n",
    "        print(\"Lexical units in the frame\")\n",
    "        print(list(fn.frame(frames_id).FE))\n",
    "        #for every lexical unit in the frame we use lesk algoritm for return the best sense in wordnet\n",
    "        for unit in list(fn.frame(frames_id).FE): \n",
    "            if(\"_\" in fn.frame(frames_id).name):\n",
    "                print(lesk(unit.split(\"_\")[0],fn.frame(frames_id).definition,True))\n",
    "            else:\n",
    "                print(lesk(unit,fn.frame(frames_id).definition,True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('land.n.04'),\n",
       " Synset('reason.n.01'),\n",
       " Synset('earth.n.02'),\n",
       " Synset('footing.n.02'),\n",
       " Synset('ground.n.05'),\n",
       " Synset('background.n.02'),\n",
       " Synset('land.n.02'),\n",
       " Synset('ground.n.08'),\n",
       " Synset('ground.n.09'),\n",
       " Synset('ground.n.10'),\n",
       " Synset('flat_coat.n.01'),\n",
       " Synset('anchor.v.01'),\n",
       " Synset('ground.v.02'),\n",
       " Synset('ground.v.03'),\n",
       " Synset('ground.v.04'),\n",
       " Synset('ground.v.05'),\n",
       " Synset('ground.v.06'),\n",
       " Synset('ground.v.07'),\n",
       " Synset('ground.v.08'),\n",
       " Synset('ground.v.09'),\n",
       " Synset('prime.v.02'),\n",
       " Synset('ground.v.11'),\n",
       " Synset('establish.v.08'),\n",
       " Synset('crunch.v.02'),\n",
       " Synset('grate.v.04'),\n",
       " Synset('labor.v.02'),\n",
       " Synset('grind.v.04'),\n",
       " Synset('grind.v.05'),\n",
       " Synset('grind.v.06'),\n",
       " Synset('grind.v.07')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"ground\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
